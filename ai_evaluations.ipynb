{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deltorobarba/sciences/blob/master/ai_evaluations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Vertex AI Evaluations**"
      ],
      "metadata": {
        "id": "dkHA4NglD5u8"
      },
      "id": "dkHA4NglD5u8"
    },
    {
      "cell_type": "code",
      "source": [
        "# Update project ID, GCP bucket name and name of TMX file manually:\n",
        "\n",
        "PROJECT_ID = \"YOUR-PROJECT-ID\"               # <--- UPDATE THIS\n",
        "LOCATION = \"us-central1\"\n",
        "BUCKET_NAME = \"translations-eval\" # <--- UPDATE THIS\n",
        "BUCKET_URI = f\"gs://{BUCKET_NAME}\"\n",
        "TMX_GCS_PATH = \"samples.tmx\"    # <--- UPLOAD THIS\n",
        "LOCAL_TMX_FILE = \"samples.tmx\""
      ],
      "metadata": {
        "id": "x2GtCQTjx7-o"
      },
      "id": "x2GtCQTjx7-o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade google-cloud-aiplatform google-cloud-storage -q\n",
        "%pip install matplotlib seaborn langdetect -q\n",
        "%pip install --upgrade --user --quiet google-cloud-aiplatform[evaluation]\n",
        "\n",
        "!pip install google-cloud-translate==2.0.1 -q\n",
        "!pip install --upgrade google-cloud-translate -q\n",
        "\n",
        "import xml.etree.ElementTree as ET\n",
        "import json\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter, defaultdict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.cloud import aiplatform, storage\n",
        "from google.cloud import translate_v3 as translate\n",
        "import vertexai\n",
        "from vertexai.tuning import sft\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from datetime import datetime\n",
        "import re\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# For language detection\n",
        "from langdetect import detect, detect_langs"
      ],
      "metadata": {
        "id": "l4-2YlW2AhuU"
      },
      "id": "l4-2YlW2AhuU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Vertex AI\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "# Utility Functions\n",
        "def download_from_gcs(bucket_name, source_blob_name, destination_file_name):\n",
        "    \"\"\"Downloads a file from GCS and returns the local path.\"\"\"\n",
        "    print(f\"--- Downloading {source_blob_name} ---\")\n",
        "    storage_client = storage.Client(project=PROJECT_ID)\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(source_blob_name)\n",
        "    blob.download_to_filename(destination_file_name)\n",
        "    print(f\"Successfully downloaded to {destination_file_name}\")\n",
        "    return destination_file_name\n",
        "\n",
        "def upload_to_gcs(bucket_name, source_file_name, destination_blob_name):\n",
        "    \"\"\"Uploads a file to GCS and returns the GCS URI.\"\"\"\n",
        "    print(f\"--- Uploading {source_file_name} ---\")\n",
        "    storage_client = storage.Client(project=PROJECT_ID)\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(destination_blob_name)\n",
        "    blob.upload_from_filename(source_file_name)\n",
        "    gcs_uri = f\"gs://{bucket_name}/{destination_blob_name}\"\n",
        "    print(f\"Successfully uploaded to {gcs_uri}\")\n",
        "    return gcs_uri"
      ],
      "metadata": {
        "id": "ZgUnsbm4RfGV"
      },
      "id": "ZgUnsbm4RfGV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Vertex AI Evaluations\n",
        "# ============================================================================\n",
        "import pandas as pd\n",
        "import re\n",
        "from vertexai.evaluation import EvalTask\n",
        "from vertexai.evaluation.metrics import pointwise_metric\n",
        "\n",
        "try:\n",
        "    import notebook_utils\n",
        "except ImportError:\n",
        "    print(\"Warning: 'notebook_utils' module not found. Result display might be basic.\")\n",
        "    class notebook_utils:\n",
        "        @staticmethod\n",
        "        def display_eval_result(result):\n",
        "            print(result)\n",
        "\n",
        "metrics = [\n",
        "    \"bleu\",\n",
        "    pointwise_metric.Comet(version=\"COMET_22_SRC_REF\"),\n",
        "    pointwise_metric.MetricX(version=\"METRICX_24_SRC\"),\n",
        "]\n",
        "\n",
        "all_eval_results = {}\n",
        "\n",
        "# Check if df dictionary exists\n",
        "if 'ground_truth_dfs' not in locals() or not ground_truth_dfs:\n",
        "    print(\"\\n 'ground_truth_dfs' dictionary not found or is empty. Please re-run the previous steps first.\")\n",
        "else:\n",
        "    for lang_code, df in ground_truth_dfs.items():\n",
        "        print(f\"\\n\\n--- Starting Evaluation for: {lang_code.upper()} ---\")\n",
        "\n",
        "        eval_df_prepared = df.copy()\n",
        "        eval_df_prepared.rename(columns={\n",
        "            'source_text': 'content',    # Original (English) text\n",
        "            'prediction': 'response',    # Model's translated output\n",
        "            'reference_text': 'reference' # Human-translated reference text\n",
        "        }, inplace=True, errors='ignore') # Added errors='ignore' for safety\n",
        "\n",
        "        if 'reference' not in eval_df_prepared.columns:\n",
        "            print(f\"    Skipping {lang_code}: The required 'reference' column was not found.\")\n",
        "            print(\"      Please ensure your DataFrame has a 'reference_text' column.\")\n",
        "            continue\n",
        "\n",
        "        safe_lang_code = re.sub(r'[^a-z0-9-]', '', lang_code.lower())\n",
        "        experiment_name = f\"translation-eval-{safe_lang_code}\"\n",
        "        print(f\"   Vertex AI Experiment Name: {experiment_name}\")\n",
        "\n",
        "        try:\n",
        "            print(\"   Initializing evaluation task...\")\n",
        "            eval_task = EvalTask(\n",
        "                dataset=eval_df_prepared,\n",
        "                metrics=metrics,\n",
        "                experiment=experiment_name\n",
        "            )\n",
        "\n",
        "            print(\"   Running evaluation... (This can take several minutes per language)\")\n",
        "            eval_result = eval_task.evaluate()\n",
        "            all_eval_results[lang_code] = eval_result\n",
        "            print(f\"  Evaluation for {lang_code} complete.\")\n",
        "\n",
        "            print(f\"\\n--- Results for {lang_code} ---\")\n",
        "            notebook_utils.display_eval_result(eval_result)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  An error occurred during evaluation for {lang_code}: {e}\")\n",
        "            print(\"   Skipping to the next language.\")\n",
        "\n",
        "# --- Final Summary ---\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"AUTOMATIC EVALUATIONS SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if not all_eval_results:\n",
        "    print(\"\\nNo evaluations were successfully completed.\")\n",
        "else:\n",
        "    print(\"\\n\")\n",
        "    print(\"* row_count is number of sentences evaluated (more sentences make the results more reliable)\")\n",
        "    print(\"* bleu/mean measures word and phrase overlap with a human reference (precision). On a scale of 0 to 1, a score above 0.4 is usable and above 0.6 is high quality.\")\n",
        "    print(\"* bleu/std measures consistency of BLEU score. A low value is good (stable quality); a high value is bad (erratic quality).\")\n",
        "    print(\"* comet/mean measures semantic similarity (meaning) using an AI model. A score above 0.8 is good; below 0.6 suggests errors.\")\n",
        "    print(\"* comet/std measures consistency of semantic quality. A low value is good (reliable meaning); a high value is bad (unreliable meaning).\")\n",
        "    print(\"* metricx/mean measures semantic quality using an advanced AI model. A score above 10 is good, above 15 is excellent, and below 5 is poor.\")\n",
        "    print(\"* metricx/std measures consistency of semantic quality. A low value is good (consistently accurate); a high value is bad (unpredictable).\")\n",
        "    print(\"\\n \")\n",
        "    summary_data = []\n",
        "    for lang_code, result in all_eval_results.items():\n",
        "        metrics_dict = result.summary_metrics\n",
        "        metrics_dict['language'] = lang_code\n",
        "        summary_data.append(metrics_dict)\n",
        "\n",
        "    summary_df = pd.DataFrame(summary_data)\n",
        "    cols = ['language'] + [col for col in summary_df.columns if col != 'language']\n",
        "    summary_df = summary_df[cols]\n",
        "\n",
        "    display(summary_df)"
      ],
      "metadata": {
        "id": "l70ct8nH97jY"
      },
      "id": "l70ct8nH97jY",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}