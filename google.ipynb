{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "G76hTQm13NKf",
        "8sIpq5OYIQbi",
        "IbQ5pdlD1Q_a",
        "-ZXm6SgN5N9V",
        "wFgNAsqXIBFQ",
        "Dd7EdPX646jK"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deltorobarba/sciences/blob/master/google.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"blue\">**Machine Learning ü¶ãüñ≤Ô∏è**"
      ],
      "metadata": {
        "id": "9wUgGWqn1Pc9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_4000.png)"
      ],
      "metadata": {
        "id": "LRrfRNva1PAl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*This notebook is an attempt to structure different aspects of machine learning. Additionally, it contains a collection of links for technical repos used for customer reference. Given the pace of development I provide links to  updated code repos.*"
      ],
      "metadata": {
        "id": "dZI62XdRxFIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-adk\n",
        "!pip install google-genai\n",
        "!pip install google-cloud-aiplatform"
      ],
      "metadata": {
        "id": "ZKGapxnLrtVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color=\"blue\">- - - *Google Agent Development Kit - - -*"
      ],
      "metadata": {
        "id": "G76hTQm13NKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Google Agent Development Kit**\n",
        "* Qwiklabs: [Get started with Google Agent Development Kit (ADK)](https://explore.qwiklabs.com/focuses/8287?parent=catalog)\n",
        "* https://github.com/GoogleCloudPlatform/agent-starter-pack/tree/main/agents/adk_base\n",
        "* https://google.github.io/adk-docs/\n",
        "* https://github.com/google/adk-python\n",
        "* https://github.com/google/adk-samples\n",
        "* https://google.github.io/adk-docs/#what-is-agent-development-kit\n",
        "* https://google.github.io/adk-docs/deploy/agent-engine/#create-your-agent\n",
        "\n",
        "*You're starting a genai project. When would you chose an \"agent\" via ADK, vs developing code with the vertex genai SDK ? - I would recommend trying the lab as it would clarify it for you. If I were to go DIY without the ADK (or other frameworks), Gemini would only tell me which function to call and the input params so I would need to execute the function in my code and pass the context back to Gemini and proceed from there. That is not necessarily difficult but when you have a complex setup with composable agents doing smaller tasks, it is much easier to use a framework like ADK to orchestrate it and manage state between them.*\n",
        "\n",
        "**w/ Agent Engine**\n",
        "* How to deploy applications built with ADK: We recommend using Agent Engine, for out of the box state and memory management, monitoring, logging, security, etc. However, you can deploy on your compute surface of choice (eg, Cloud Run).\n",
        "* https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/overview\n",
        "\n",
        "**w/ Agent Space**\n",
        "* ADK is used to develop the agents made available via AgentSpace and the new Customer Engagement Suite. ADK is also being leveraged by other PAs within Google.\n",
        "* https://cloud.google.com/blog/products/ai-machine-learning/introducing-customer-engagement-suite-with-google-ai?e=48754805\n",
        "\n",
        "**w/ Vertex AI Vector Search**\n",
        "* Announce the integration of Vertex AI Vector Search with the Agent Starter Pack! Start agentic RAG in minutes with Vertex AI Vector Search and Agent Starter Pack:\n",
        "* https://cloud.google.com/vertex-ai/docs/vector-search/overview\n",
        "* https://github.com/GoogleCloudPlatform/agent-starter-pack\n",
        "* Vertex AI Vector Search is our consistently fast and scalable managed vector search designed for any workload. One of the developer pain points is the long time-to-value required to stand up the infrastructure and to integrate robust data ingestion pipelines.\n",
        "* Now, a developer can use the Agent Starter Pack to stand up a scalable Agentic RAG solution with a ready-to-go data pipeline with two commands:\n",
        "* Install the Agent Starter pack:\n",
        "```\n",
        "pip install --upgrade agent-starter-pack\n",
        "```\n",
        "* Create a new agent project with Agentic RAG and Vector Search:\n",
        "```\n",
        "agent-starter-pack create my-awesome-agent -a agentic_rag -ds vertex_ai_vector_search\n",
        "```\n",
        "* The agent-starter-pack create command bootstraps your entire project in one go - automatically generating the complete structure, agent code (like the agentic_rag template), data pipeline, scalable deployment infrastructure via Terraform, and CI/CD and load tests. Developers can then customize and extend the code to their use case.\n",
        "\n",
        "**Additional Learnings**\n",
        "* https://github.com/sokart/adk-walkthrough\n",
        "* https://medium.com/@sokratis.kartakis/from-zero-to-multi-agents-a-beginners-guide-to-google-agent-development-kit-adk-b56e9b5f7861\n",
        "* https://medium.com/google-cloud/how-to-deploy-adk-agents-onto-google-cloud-run-5bbd62049a19\n",
        "* https://medium.com/google-cloud/build-ai-agents-your-way-on-google-cloud-7e64e76550bc\n",
        "* https://medium.com/google-cloud/connect-act-google-adk-agents-with-gcp-integration-connectors-to-perform-tasks-across-100-ca10a3fd5334\n",
        "* https://www.youtube.com/watch?v=zgrOwow_uTQ\n",
        "* https://www.forbes.com/sites/janakirammsv/2025/04/14/google-unveils-the-most-comprehensive-agent-strategy-at-cloud-next-2025/\n",
        "\n",
        "**Agent Starter Pack now includes ADK samples**\n",
        "* Agent Starter Pack now includes ADK samples - Build Production Agents Faster! We've enhanced the Agent Starter Pack ‚Äì a collection of templates for building production-ready AI agents ‚Äì by showcasing the new Agent Development Kit (ADK)!\n",
        "* Github repo: GoogleCloudPlatform/agent-starter-pack and go/agent-starter-pack\n",
        "* Jumpstart your projects with two powerful new ADK-based templates:\n",
        "* adk_base: A simple agent using ADK. Ideal for starting with ADK.\n",
        "* agentic_rag: A RAG agent leveraging ADK for document Q&A, integrated with Vertex AI Search and Vector Search. Including a data pipeline for embedding generation leveraging BigQuery BigFrames.\n",
        "* Mix and match with the excellent samples in google/adk-samples : https://github.com/google/adk-samples\n",
        "* See It Live: 30s Overview: Quick glimpse of an ADK agent via the Starter Pack. https://www.youtube.com/watch?v=Wylf4HGCAZU\n",
        "* Full Production Workflow Demo: From code to deployment with Terraform, CI/CD & Monitoring. https://www.youtube.com/watch?v=UyCH81lUhKM\n",
        "* Deep Dive into Agentic RAG: Explore data ingestion and deployment for the ADK RAG agent. https://www.youtube.com/watch?v=CLrkOKL984Q\n",
        "* Get Hands-On in 60 Seconds:\n",
        "\n",
        "```\n",
        "# Create and activate a Python virtual environment\n",
        "python -m venv venv && source venv/bin/activate\n",
        "\n",
        "# Install the agent starter pack\n",
        "pip install agent-starter-pack\n",
        "\n",
        "# Create a new agent project\n",
        "agent-starter-pack create my-awesome-agent\n",
        "```\n",
        "\n",
        "* Get a fully functional agent structure with built-in best practices, ready for your logic!\n",
        "* Try it in Firebase Studio with zero setup: https://studio.firebase.google.com/new?template=https%3A%2F%2Fgithub.com%2FGoogleCloudPlatform%2Fagent-starter-pack%2Ftree%2Fmain%2Fsrc%2Fresources%2Fidx\n",
        "* Run hackathons and workshops on building Agents E2E via Qwiklabs resource (available to Googlers, customers, and partners) -start here: https://sites.google.com/corp/google.com/agent-starter-pack/run-a-labhack-with-qwiklabs\n",
        "\n",
        "\n",
        "**A2A (Agent2Agent Protocol)**\n",
        "* https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/\n",
        "* https://github.com/google/A2A\n",
        "* https://google.github.io/A2A/#/\n",
        "* https://nikhilpurwant.com/post/tech-genai-adk-mcp/\n",
        "\n",
        "**Private Preview for Vertex AI Memory Bank**\n",
        "* a new capability within the Vertex AI Agent Engine designed to bring persistent, long-term memory to AI agents.\n",
        "* [Slides 1](https://docs.google.com/presentation/d/1Q8bcdVM0YO47jTS5hlRxVhl_1EAumK0dsLHRgajWW9I/preview?slide=id.g34482d1db9c_0_0) and [Slides 2](https://docs.google.com/document/d/1cUYdIzus1GZVJL1MrXBHrnM-Fb9LTVgyRfI_ina4WlI/preview?resourcekey=0-wwqp-jaaHYcxF_z_vSSn8A&tab=t.0#heading=h.dg36ftkj3jlt)\n",
        "\n",
        "**DWS Flex GPUs**\n",
        "* DWS Flex supports all GPUs. Only G2, A2, A3, and newer will have DWS specific pools. So for T4 and older there may not be as much obtainability gain since the experience will be the same as on-demand.\n",
        "* [NDA Required] DWS Customer Presentation: go/dws-pitch for pricing\n",
        "\n",
        "**Translation**\n",
        "* Tuning on TranslationLLM (which follows the same UX experience and technology stack as Gemini SFT) in Public Preview.\n",
        "* We ultimately expect it to replace AutoML Translation, so we are not investing further in AutoML Translation.\n",
        "* For training of a custom model please see the documentation\n",
        "* https://cloud.google.com/translate/docs/advanced/custom-translations\n",
        "* Supported langauges: https://cloud.google.com/translate/docs/languages\n",
        "\n",
        "**Appendix: Agent Dev Kit**\n",
        "* Flexible Orchestration: Support for diverse multi-agent topologies, including the ability to invoke remote agents via MCP.\n",
        "* Integrated Developer Tooling: Develop and iterate locally with ease. ADK includes tools like a command-line interface (CLI) and a Developer UI.\n",
        "* Rich tool ecosystem: Pre-built tools like code execution, Vertex AI Search connector, Vertex RAG connector, etc. Also, pre-built tools from the CrewAI or LangChain projects can be used as tools in ADK. Moreover, it has built-in support for long running async tools.\n",
        "* Support for deterministic logic: ADK enables interleaving deterministic logic with LLM driven reasoning. This enables building LLM driven agents that can handle edge conditions or critical situations with deterministic code.\n",
        "* Built-in streaming support: Native bidirectional audio/video streaming support, to enable agents that can have a natural human-like conversation over audio and video.\n",
        "* Broad LLM Support: While optimized for Google's Gemini models, the framework is designed for flexibility, allowing integration with various LLMs."
      ],
      "metadata": {
        "id": "wXQ6yE1t3TZr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/vertex_0002.png)"
      ],
      "metadata": {
        "id": "hR0nMs5SZKq5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "BK2QcIo2TbhS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color=\"blue\">*- - - Models - - -*"
      ],
      "metadata": {
        "id": "8sIpq5OYIQbi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Large Language Models**\n",
        "* **Gemini**\n",
        "  * https://cloud.google.com/vertex-ai/generative-ai/docs/live-api\n",
        "  * Model Optimizer: https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/vertex-ai-model-optimizer (Don't know which Gemini model to use? ü§î Vertex AI Model Optimizer is here!Vertex AI Model Optimizer is a smart model router that helps you selecting the most appropriate Gemini model based on your cost and quality preferences for each prompt with your for specific use case.)\n",
        "  * Rate Limits: https://ai.google.dev/gemini-api/docs/rate-limits#current-rate-limits\n",
        "  * Sec Gemini v1: https://security.googleblog.com/2025/04/google-launches-sec-gemini-v1-new.html\n",
        "* **Llama**: https://ai.meta.com/blog/llama-4-multimodal-intelligence/\n",
        "\n",
        "**Small Language Models**\n",
        "* Gemma: https://blog.google/technology/developers/gemma-3/\n"
      ],
      "metadata": {
        "id": "r-2MjuYLqHgu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "DfC-jRqhTc8D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color=\"blue\">*- - - Training & Tuning - - -*"
      ],
      "metadata": {
        "id": "IbQ5pdlD1Q_a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Introduction to Tuning: https://cloud.google.com/vertex-ai/generative-ai/docs/models/tune-models*\n",
        "\n",
        "**Model Garden**\n",
        "* **PEFT**: https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/explore-models\n",
        "  * Example: **Mistral**: https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_mistral_peft_tuning.ipynb\n",
        "  * Example: **LLama3** https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_pytorch_llama3_finetuning.ipynb\n",
        "* Managed PEFT for open-weight models: pending\n",
        "* **Full finetuning**: released\n",
        "* **DPO - Direct Preference Optimization**: directly optimizes the LLM's policy using a dataset of human preferences. https://arxiv.org/pdf/2305.18290.pdf (pending)\n",
        "* **Continuous Pretraining**: bring your own custom LoRA (end Q2) and tokenspace\n",
        "\n",
        "**Vertex AI**\n",
        "* **PEFT**:\n",
        "  * Example: **Llama2** fine-tuning with LoRA (and serving on TPUv5e) https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/training/tpuv5e_llama2_pytorch_finetuning_and_serving.ipynb\n",
        "* **Supervised Finetuning**:\n",
        "  * Example: **SFT for Gemini** https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini-supervised-tuning\n",
        "  * Code example: https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/tuning/sft_gemini_summarization.ipynb\n",
        "* **RLHF Tuning**: https://cloud.google.com/blog/products/ai-machine-learning/rlhf-on-google-cloud?e=48754805\n",
        "* Ray on Vertex (managed): https://cloud.google.com/vertex-ai/docs/open-source/ray-on-vertex-ai/overview\n",
        "  * Example with Gemma: https://developers.googleblog.com/en/get-started-with-gemma-on-ray-on-vertex-ai/\n",
        "  * Example: Scale with RoV https://medium.com/google-cloud/ray-on-vertex-ai-lets-get-it-started-7a9f8360ea25\n",
        "\n",
        "**Other Options**\n",
        "* Ray on GKE (with kuberay): https://cloud.google.com/kubernetes-engine/docs/add-on/ray-on-gke/concepts/overview\n",
        "* [Axolotl](https://axolotl.ai/) (finetune multiple GPU)\n",
        "* [Unsloth](https://unsloth.ai/) (finetune single GPU)\n",
        "* Dask\n",
        "* Spark\n",
        "* Infinipod\n",
        "* Horovod (distributed training): https://cloud.google.com/vertex-ai/docs/training/distributed-training\n",
        "* Cluster Director for Slurm: https://cloud.google.com/ai-hypercomputer/docs/cluster-director\n",
        "\n",
        "*Pending: * **ACT - Action-Based Contrastive Self-Training** for Multi-turn Conversations: https://arxiv.org/pdf/2406.00222, See: https://huggingface.co/docs/trl/en/index .  ACT consistently outperforms standard in-context learning, fine-tuning and DPO methods in three diverse conversational tasks (PACIFIC, Abg-CoQA, and AmbigSQL)*\n",
        "* **PEFT - Parameter-efficient fine-tuning** (with LoRA or qLoRA: https://arxiv.org/abs/2106.09685):\n",
        "  * bitsandbytes for 8bit qLoRA (k-bit quantization): https://huggingface.co/docs/bitsandbytes/index\n",
        "  * Code: https://codelabs.developers.google.com/llm-finetuning-supervised#0\n",
        "  * **Code**: [Use PEFT & bitsandbytes to finetune a LoRa checkpoint](https://colab.research.google.com/drive/14xo6sj4dARk8lXZbOifHEn1f_70qNAwy?usp=sharing#scrollTo=7650BSUPZh0Y)\n",
        "  * Video: [Fine-tuning LLMs with PEFT and LoRA](https://www.youtube.com/watch?v=Us5ZFp16PaU&t=393s)\n"
      ],
      "metadata": {
        "id": "7zYq3k7xHwx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=16, #attention heads\n",
        "    lora_alpha=32, #alpha scaling\n",
        "    # target_modules=[\"q_proj\", \"v_proj\"], #if you know the\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\" # set this for CLM or Seq2Seq\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, config)\n",
        "print_trainable_parameters(model)"
      ],
      "metadata": {
        "id": "nZCA41p_jB4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/vertex_0001.png)"
      ],
      "metadata": {
        "id": "PAXBE05TiGnR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "PrryI2TLTlbJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color=\"blue\">*- - - Serving - - -*"
      ],
      "metadata": {
        "id": "-ZXm6SgN5N9V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Interface**:\n",
        "  * FastAPI and Gradio\n",
        "  * Special LLM:\n",
        "    * vLLM\n",
        "    * Hex-LLM\n",
        "    * Ollama (local)\n",
        "  * General inference: Triton, kserve, SaxML with PyTorch (multi-host TPUs). Example Triton + GKE Autopilot for inference https://www.youtube.com/watch?v=HT2_jdMw6u0\n",
        "* **Considerations**:\n",
        "  * Stream or batch (e.g. vLLM batch - inference only with large throughput single endpoint),\n",
        "  * autoscaling (e.g. Prometheus in GKE)\n",
        "  * TCO\n",
        "* **Serving via Vertex AI**\n",
        "  * Serving multiple LoRA adapters of Open Models on Vertex AI with Hugging Face\n",
        "  * NEW: Multi-hosting and serving LLMs faster on Vertex AI\n",
        "  * Register and Versionize Models (predictive AI): Vertex AI Model Registry and Import models to Vertex AI\n",
        "* **Serving via Model Garden**\n",
        "  * Model Garden. Deploy Models from Models Garden (code). Deploy and inference Gemma\n",
        "  * Introducing the new Vertex AI Model Garden CLI and SDK\n",
        "  * Serving with Hex-LLM on TPU via Model Garden (code example)\n",
        "  * Feature: speculative decoding (research)\n",
        "* **Serving via Cloud Run**\n",
        "  * GPU on Cloud Run: fully managed, with no extra drivers or libraries needed\n",
        "  * Open weight models: How to deploy Llama 3.2-1B-Instruct model with Google Cloud Run\n",
        "* **Serving via GKE**\n",
        "  * Serve an LLM using GPUs on GKE with vLLM  and Serve an LLM using TPUs on GKE with vLLM\n",
        "  * Recipe for GPU inference via AI Hypercompute (on GKE). Try with Llama 70B instead of 405B just change single configuration setting\n",
        "* **Serving via DataFlow ML**\n",
        "  * Run ML inference by using vLLM on GPUs | Dataflow ML\n"
      ],
      "metadata": {
        "id": "GKDnpPGw5UHk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "qp7Z1g5zTm5j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color=\"blue\">*- - - Observability & Evaluation - - -*"
      ],
      "metadata": {
        "id": "wFgNAsqXIBFQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<u>Monitoring</u> tells you <u>if</u> there's a problem**.\n",
        "* Monitoring involves tracking high-level metrics related to LLM performance.. Answers: \"Is system running smoothly?\" \"Are there performance bottlenecks?\" Key metrics include latency, throughput, error rates, and resource utilization. It sets up alerts for when those metrics deviate from expected values.\n",
        "* Metrics: Request Volume (incl. identify usage anomaly, sudden spikes, drops), Request Duration (network latency, response time),  Costs, Tokens Counters\n",
        "* General monitoring: https://cloud.google.com/monitoring/docs\n",
        "* Predictive AI Monitoring: https://cloud.google.com/vertex-ai/docs/model-monitoring/overview\n",
        "* Generative AI Monitoring: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-observability"
      ],
      "metadata": {
        "id": "-Sf1wjTFIIQb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<u>Tracing</u> helps understand <u>why</u> the problem occurred.**   \n",
        "* Traceability provides a detailed, granular view of the execution flow within the LLM application. It helps understand how individual requests are processed and how different components interact. Answer: \"What steps did the LLM take to generate this response?\" and \"Where did an error occur in the process?\"\n",
        "* Traces: Request Metadata: Temperature, top_p, Model Name or Version, Prompt Details. Response Metadata: Tokens, Cost, Response Details."
      ],
      "metadata": {
        "id": "Iy03s6XkIK3D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<u>Evaluation</u> helps you to understand <u>how good</u> the LLM is performing**\n",
        "* Read: https://medium.com/google-cloud/llms-evaluation-on-gcp-9186fad73f22\n",
        "* Evaluation focuses on assessing the quality and accuracy of the LLM's outputs. It involves measuring metrics related to: Accuracy and relevance, Bias and fairness, Hallucinations, Safety and security. Evaluation is crucial for ensuring that the LLM is performing as expected and meeting desired standards\n",
        "* Providers: LangSmith, Traceloop, Arize, Ragas, MLflow, Alibi\n",
        "* **Overview**: https://cloud.google.com/vertex-ai/generative-ai/docs/models/evaluation-overview\n",
        "* **Judge Model**: https://cloud.google.com/vertex-ai/generative-ai/docs/models/evaluate-judge-model: After running your LLM evaluation, you can now compare the judge model's outputs against human preferences using metrics like balanced accuracy, F1 score, and a confusion matrix.\n",
        "* **AutoSxS** (pairwise model-based evaluation: https://cloud.google.com/vertex-ai/generative-ai/docs/models/side-by-side-eval\n",
        "* **Computation-based evaluation**: https://cloud.google.com/vertex-ai/generative-ai/docs/models/computation-based-eval-pipeline\n"
      ],
      "metadata": {
        "id": "Duo9_CDvb_QZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a pointwise metric with two criteria: Fluency and Entertaining.\n",
        "custom_text_quality = PointwiseMetric(\n",
        "    metric=\"custom_text_quality\",\n",
        "    metric_prompt_template=PointwiseMetricPromptTemplate(\n",
        "        criteria={\n",
        "            \"fluency\": (\n",
        "                \"Sentences flow smoothly and are easy to read, avoiding awkward\"\n",
        "                \" phrasing or run-on sentences. Ideas and sentences connect\"\n",
        "                \" logically, using transitions effectively where needed.\"\n",
        "            ),\n",
        "            \"entertaining\": (\n",
        "                \"Short, amusing text that incorporates emojis, exclamations and\"\n",
        "                \" questions to convey quick and spontaneous communication and\"\n",
        "                \" diversion.\"\n",
        "            ),\n",
        "        },\n",
        "        rating_rubric={\n",
        "            \"1\": \"The response performs well on both criteria.\",\n",
        "            \"0\": \"The response is somewhat aligned with both criteria\",\n",
        "            \"-1\": \"The response falls short on both criteria\",\n",
        "        },\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "pHdtyU4xdxSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![ggg](https://cloud.google.com/static/vertex-ai/generative-ai/docs/images/observability-dashboard.png)"
      ],
      "metadata": {
        "id": "PpYbGl3fdNZJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5QAIJWtgTon2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color=\"blue\">*- - - Miscellaneous - - -*"
      ],
      "metadata": {
        "id": "Dd7EdPX646jK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* TPU Ironwood: https://blog.google/products/google-cloud/ironwood-tpu-age-of-inference/ - Scaling to 9,216 chips *per pod* for a 42.5 Exaflops, it's not just powerful ‚Äì it's in a league of its own, boasting >24x the compute of the current top supercomputer, El Capitan\n",
        "* Google Science Platform: https://blog.google/products/google-cloud/scientific-research-tools-ai/\n",
        "* https://www.thealgorithmicbridge.com/p/google-is-winning-on-every-ai-front\n",
        "* Learn: https://www.cloudskillsboost.google/paths/1283"
      ],
      "metadata": {
        "id": "nx1nUj_r3qGR"
      }
    }
  ]
}