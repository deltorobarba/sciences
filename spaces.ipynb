{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spaces.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qYW5u_0Oi7l5",
        "tQRaw6wfNOpR",
        "bt1ud5jc4UUB",
        "1k-wmgpkP8lv",
        "SHXnaFUeQBL6",
        "xU32us9ZQouN",
        "nwOcv6tLTkxl",
        "2KesWFfaTmuu",
        "iVuurd_GTqys",
        "bHE_58TCK5mP",
        "zI1toWT6AZet",
        "7oaxbCPG0PUB",
        "L7u1GiAGVvzL",
        "g2VqyxFgIRLt",
        "dfT-0QZZm8VW",
        "hDrk6VPEtOU2",
        "rXt3-c9EhID7",
        "gD8HZ1Q1giLt",
        "15ok6ieBgYkv",
        "SAdXAeihnHMA",
        "yO5uuQMehFZD",
        "UXNI2l-ru6OO",
        "ajT03d8Bzwz_",
        "CXBpZ1M8zNi5",
        "ZrVKpOHIzWHG",
        "O1hoL_o6Zh_H",
        "mISGLzNFniMx",
        "HbZOslj1eRla",
        "fFzrPn6HYJt9",
        "rZlz94XCYE8Q",
        "ug1sNzCsdMGh",
        "D1mImehPm69J",
        "X1tE5YQRlE54",
        "iFheGZB5u2fk"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deltorobarba/machinelearning/blob/master/spaces.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Aoj2PpxvDQV",
        "colab_type": "text"
      },
      "source": [
        "# **Spaces**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U5_6xH7tAQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ostHcxEvNZ5r",
        "colab_type": "text"
      },
      "source": [
        "![Normed Vector Space](https://upload.wikimedia.org/wikipedia/en/7/74/Mathematical_Spaces.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkYQO6LE2R1b",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Space_(mathematics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYW5u_0Oi7l5",
        "colab_type": "text"
      },
      "source": [
        "## **Inner product space (Pr√§hilbertraum bzw. Skalarprodukt)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtcOpkYQjFKx",
        "colab_type": "text"
      },
      "source": [
        "* Vektorraum, auf dem ein inneres Produkt definiert ist\n",
        "\n",
        "* In linear algebra, an inner product space is a vector space with an additional structure called an inner product. This additional structure associates each pair of vectors in the space with a scalar quantity known as the inner product of the vectors\n",
        "\n",
        "* Geometric interpretation of the angle between two vectors defined using an inner product. Inner products allow the rigorous introduction of intuitive geometrical notions such as the length of a vector or the angle between two vectors. They also provide the means of defining orthogonality between vectors (**zero inner product**). \n",
        "\n",
        "* Inner product spaces generalize Euclidean spaces (in which the inner product is the **dot product**, also known as the scalar product) to vector spaces of any (possibly infinite) dimension, and are studied in functional analysis. \n",
        "\n",
        "* An inner product **naturally induces an associated norm**, (|x| and |y| are the norms of x and y, in the picture) thus an inner product space is also a normed vector space. A complete space with an inner product is called a Hilbert space. \n",
        "\n",
        "* An (incomplete) space with an inner product is called a pre-Hilbert space, since its completion with respect to the norm induced by the inner product is a Hilbert space. Inner product spaces over the field of complex numbers are sometimes referred to as unitary spaces."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1QQh9gFi-WB",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Inner_product_space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQRaw6wfNOpR",
        "colab_type": "text"
      },
      "source": [
        "## **Normed Vector Spaces (Vektornormen)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bt1ud5jc4UUB",
        "colab_type": "text"
      },
      "source": [
        "### **Overview & p-Norm**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3Ek_c4p1Ldn",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Norm_(Mathematik)#Vektornormen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y23TBwgQXJuY",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Norm_(mathematics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUGbZ9CqNRHn",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Normed_vector_space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-LnUvriVm4a",
        "colab_type": "text"
      },
      "source": [
        "A normed vector space or normed space is a vector space over the real or complex numbers, on which a norm is defined. A norm is the formalization and the generalization to real vector spaces of the intuitive notion of \"length\" in the real world. A norm is a real-valued function defined on the vector space that is commonly denoted x ‚Ü¶ ‚Äñ x ‚Äñ, and has the **following properties**:\n",
        "\n",
        "1. It is **nonnegative**, that is for every vector x, one has ‚Äñx‚Äñ ‚â• 0.\n",
        "\n",
        "2. It is **positive on nonzero vectors**, that is, ‚Äñx‚Äñ = 0 ‚ü∫ x = 0.\n",
        "\n",
        "3. For every vector x, and every **scalar Œ±**, one has ‚Äñ Œ± x ‚Äñ = | Œ± | ‚Äñ x ‚Äñ.\n",
        "\n",
        "4. The **triangle inequality** holds; that is, for every vectors x and y, one has ‚Äñ x+y ‚Äñ ‚â§ ‚Äñ x ‚Äñ + ‚Äñ y ‚Äñ.\n",
        "\n",
        "A norm induces a distance by the formula d (x,y) = ‚Äñ y-x ‚Äñ.\n",
        "\n",
        "Therefore, a normed vector space is a metric space, and thus a topological vector space. An [inner product space](https://en.m.wikipedia.org/wiki/Inner_product_space) is a normed space, where the norm of a vector is the square root of the inner product of the vector by itself. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFf8p5SVJn2V",
        "colab_type": "text"
      },
      "source": [
        "**P-Norm**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUReq39VTPQM",
        "colab_type": "text"
      },
      "source": [
        "For all p ‚â• 1, the p-norms and maximum norm as defined above indeed satisfy the properties of a \"length function\" (or norm), which are that:\n",
        "\n",
        "1. only the zero vector has zero length,\n",
        "\n",
        "2. lhe length of the vector is positive homogeneous with respect to multiplication by a scalar (positive homogeneity), and\n",
        "\n",
        "3. the length of the sum of two vectors is no larger than the sum of lengths of the vectors (triangle inequality).\n",
        "\n",
        "Abstractly speaking, this means that **Rn together with the p-norm is a Banach space**. This Banach space is the Lp-space over Rn. \n",
        "\n",
        "**Any normed vector space is a metric space** by defining d(x, y) = ‚Äñ y - x ‚Äñ, see also metrics on vector spaces. (If such a space is complete, we call it a Banach space.) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeSMyh0-FK2I",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/P-Norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQlHR9FKyapX",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Norm_(Mathematik)#Vektornormen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMXH_RxXRDkr",
        "colab_type": "text"
      },
      "source": [
        "![alternativer Text](https://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Vector-p-Norms_qtl1.svg/480px-Vector-p-Norms_qtl1.svg.png)\n",
        "\n",
        "*Illustrations of unit circles (see also superellipse) in different p-norms (every vector from the origin to the unit circle has a length of one, the length being calculated with length-formula of the corresponding p).*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1k-wmgpkP8lv",
        "colab_type": "text"
      },
      "source": [
        "### **Von der p1-Norm (Summennorm) zur L1 Norm**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqKbtCMiB61r",
        "colab_type": "text"
      },
      "source": [
        "> $\\|x\\|_{1}=\\sum_{i=1}^{n}\\left|x_{i}\\right|$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4dl2ZASP_kc",
        "colab_type": "text"
      },
      "source": [
        "* Summennorm, Betragssummennorm oder 1-Norm ist in der Mathematik eine **Vektornorm**. Sie ist definiert als die Summe der Betr√§ge der Vektorkomponenten und ist eine spezielle p-Norm f√ºr die Wahl von p=1.\n",
        "\n",
        "* Die Einheitssph√§re der reellen Summennorm ist ein Kreuzpolytop mit minimalem Volumen √ºber alle p-Normen. **Daher ergibt die Summennorm f√ºr einen gegebenen Vektor den gr√∂√üten Wert aller p-Normen**. Die von der Summennorm abgeleitete Metrik ist die Manhattan-Metrik.\n",
        "\n",
        "* Die Summennorm ist im Gegensatz zur euklidischen Norm (2-Norm) **nicht von einem Skalarprodukt induziert.**\n",
        "\n",
        "* Die von der Summennorm abgeleitete Metrik ist die **Manhattan-Metrik** oder Taxi-Metrik.\n",
        "\n",
        "* Die von der Summennorm [induzierte Matrixnorm](https://de.m.wikipedia.org/wiki/Nat√ºrliche_Matrixnorm) ist die [Spaltensummennorm](https://de.m.wikipedia.org/wiki/Spaltensummennorm).\n",
        "\n",
        "* Techniques which use an L1 penalty, like LASSO, encourage solutions where many parameters are zero. \n",
        "\n",
        "* The Manhattan norm gives rise to the Manhattan distance, where the distance between any two points, or vectors, is the sum of the differences between corresponding coordinates.\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Taxicab_geometry\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Lasso_(statistics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v2FUVhEND-B",
        "colab_type": "text"
      },
      "source": [
        "![alternativer Text](https://upload.wikimedia.org/wikipedia/commons/thumb/d/d9/Euclid_Octahedron_3.svg/240px-Euclid_Octahedron_3.svg.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69gd5KqRNHzc",
        "colab_type": "text"
      },
      "source": [
        "*Der Einheitssph√§re der Summennorm ist in drei Dimensionen ein Oktaeder*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4MyKCvxQKCl",
        "colab_type": "text"
      },
      "source": [
        "**Beispiel (reeller Vektor):**\n",
        "\n",
        "Die Summennorm des reellen Vektors $x=(3,-2,6) \\in \\mathbb{R}^{3}$ ist gegeben als\n",
        "\n",
        "$\\|x\\|_{1}=|3|+|-2|+|6|=11$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ozv2tPIOKQr",
        "colab_type": "text"
      },
      "source": [
        "**Die wichtigsten Verallgemeinerungen der Summen-Norm:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T_E2UeNOdOW",
        "colab_type": "text"
      },
      "source": [
        "$\\ell^{1}-$ Norm (**Folgenraum**)\n",
        "\n",
        "* Die $\\ell^{1}$ -Norm ist die Verallgemeinerung der Summennorm auf den Folgenraum $\\ell^{1}$ der **betragsweise summierbaren Folgen** $\\left(a_{n}\\right)_{n} \\in \\mathbb{K}^{N} .$ Hierbei wird lediglich **die endliche Summe durch eine unendliche ersetzt** und die $\\ell^{\\text {t }}$ -Norm ist dann gegeben als\n",
        "\n",
        "> $\\left\\|\\left(a_{n}\\right)\\right\\|_{\\ell^{1}}=\\sum_{n=1}^{\\infty}\\left|a_{n}\\right|$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpfpULLzPBb8",
        "colab_type": "text"
      },
      "source": [
        "$L^{1}$ -Norm (**Funktionenraum**)\n",
        "\n",
        "* Weiter kann die Summennorm auf den Funktionenraum $L^{1}(\\Omega)$ der auf einer Menge $\\Omega$ betragsweise integrierbaren Funktionen verallgemeinert werden, was in zwei Schritten geschieht. Zun√§chst wird die $\\mathcal{L}^{1}$ Norm einer betragsweise Lebesgue-integrierbaren Funktion $f: \\Omega \\rightarrow \\mathbb{K}$ als\n",
        "\n",
        "> $\\|f\\|_{\\mathcal{L}^{1}(\\Omega)}=\\int_{\\Omega}|f(x)| d x$\n",
        "\n",
        "* definiert, wobei im Vergleich zur $\\ell^{1}$ -Norm lediglich die Summe durch ein Integral ersetzt wurde. Dies ist zun√§chst nur eine Halbnorm, da nicht nur die Nullfunktion, sondern auch alle Funktionen, die sich nur an einer Menge mit Lebesgue-Ma√ü Null von der Nullfunktion unterscheiden, zu Null integriert werden. \n",
        "\n",
        "* Daher betrachtet man die Menge der √Ñquivalenzklassen von Funktionen $[f] \\in L^{1}(\\Omega)$, die fast √ºberall gleich sind, und erh√§lt auf diesem $L^{1}$ -Raum die $L^{1}$ -Norm durch\n",
        "\n",
        "> $\\|[f]\\|_{L^{1}(\\Omega)}=\\|f\\|_{\\mathcal{L}^{1}(\\Omega)}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQOMzI3RBEU2",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Summennorm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHXnaFUeQBL6",
        "colab_type": "text"
      },
      "source": [
        "### **Von der p2-Norm (Euklidische Norm) zur L2 Norm**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3yL08xkQGbj",
        "colab_type": "text"
      },
      "source": [
        "* Die euklidische Norm, Standardnorm oder 2-Norm ist eine in der Mathematik h√§ufig verwendete Vektornorm. Im zwei- und dreidimensionalen euklidischen Raum entspricht die euklidische Norm der anschaulichen L√§nge oder dem Betrag eines Vektors und kann mit dem Satz des Pythagoras berechnet werden. \n",
        "\n",
        "* Die euklidische Norm ist eine **von einem Skalarprodukt induzierte Norm** (im Ggs zur p1-Norm)\n",
        "\n",
        "* Techniques which use an L2 penalty, like ridge regression, encourage solutions where most parameter values are small.\n",
        "\n",
        "* Exkurs: [Elastic Net](https://en.m.wikipedia.org/wiki/Elastic_net_regularization) regularization uses a penalty term that is a combination of the L1 norm and the L2 norm of the parameter vector.\n",
        "\n",
        "* The length of a vector x = (x1, x2, ..., xn) in the n-dimensional real vector space Rn is usually given by the **Euclidean norm**:\n",
        "\n",
        "> $\\|x\\|_{2}=\\left(x_{1}^{2}+x_{2}^{2}+\\cdots+x_{n}^{2}\\right)^{1 / 2}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSVhAEwxB_hW",
        "colab_type": "text"
      },
      "source": [
        "> $\\|x\\|_{2}=\\sqrt{\\sum_{i=1}^{n}\\left|x_{i}\\right|^{2}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4u2sHf11vdf",
        "colab_type": "text"
      },
      "source": [
        "Die Euclidean Norm besitzt als eine von einem Skalarprodukt [induzierte Norm](https://de.m.wikipedia.org/wiki/Skalarproduktnorm) **neben den [drei Normaxiomen](https://de.m.wikipedia.org/wiki/Norm_(Mathematik)#Definition) eine Reihe weiterer Eigenschaften**:\n",
        "\n",
        "* die G√ºltigkeit der [Cauchy-Schwarz-Ungleichung](https://de.m.wikipedia.org/wiki/Cauchy-Schwarzsche_Ungleichung)\n",
        "* der [Parallelogrammgleichung](https://de.m.wikipedia.org/wiki/Parallelogrammgleichung)\n",
        "* sowie eine Invarianz unter unit√§ren Transformationen (Die euklidische Norm √§ndert sich also unter unit√§ren Transformationen nicht. F√ºr reelle Vektoren sind solche Transformationen beispielsweise Drehungen des Vektors um den Nullpunkt. Diese Eigenschaft wird zum Beispiel bei der numerischen L√∂sung linearer Ausgleichsprobleme √ºber die **Methode der kleinsten Quadrate mittels QR-Zerlegungen genutzt**.)\n",
        "\n",
        "F√ºr orthogonale Vektoren erf√ºllt die euklidische Norm selbst eine allgemeinere Form des Satzes des Pythagoras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbyU4goN2tS_",
        "colab_type": "text"
      },
      "source": [
        "* Von der euklidischen Norm werden Begriffe wie der euklidische Abstand und die euklidische Topologie abgeleitet. \n",
        "\n",
        "* Sie **kann auf unendlichdimensionale Vektorr√§ume verallgemeinert werden**, beispielsweise auf **Folgenr√§ume durch die ‚Ñì2-Norm** und auf **Funktionenr√§ume durch die [L2-Norm](https://de.m.wikipedia.org/wiki/Lp-Raum#Der_Hilbertraum_L2) (Hilbertraum L2)**.\n",
        "\n",
        "* Sieht man eine Matrix mit reellen oder komplexen Eintr√§gen als entsprechend langen Vektor an, so kann die euklidische Norm auch f√ºr Matrizen definiert werden und hei√üt dann [**Frobeniusnorm**](https://de.m.wikipedia.org/wiki/Frobeniusnorm). Die euklidische Norm kann auch auf unendlichdimensionale Vektorr√§ume √ºber den reellen oder komplexen Zahlen verallgemeinert werden und hat dann zum Teil eigene Namen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6av7qXO0_rf",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Euklidische_Norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewZ2VXEjESYA",
        "colab_type": "text"
      },
      "source": [
        "See also: https://en.m.wikipedia.org/wiki/Non-Euclidean_geometry"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_25QFIacwWAd",
        "colab_type": "text"
      },
      "source": [
        "**Euklidische Norm und Einheitskreis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQufRHsJx6AL",
        "colab_type": "text"
      },
      "source": [
        "F√ºr einen gegebenen Vektor $x_{0} \\in V$ und einen Skalar $r \\in \\mathbb{K}$ mit $r>0$ hei√üt die Menge\n",
        "\n",
        "> $\\left\\{x \\in V:\\left\\|x-x_{0}\\right\\|<r\\right\\}$\n",
        "\n",
        "bzw. $\\quad\\left\\{x \\in V:\\left\\|x-x_{0}\\right\\| \\leq r\\right\\}$\n",
        "offene bzw. abgeschlossene Normkugel und die Menge\n",
        "\n",
        "> $\\left\\{x \\in V:\\left\\|x-x_{0}\\right\\|=r\\right\\}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TC_GtMMcwt1e",
        "colab_type": "text"
      },
      "source": [
        "Normsph√§re um $x_{0}$ mit Radius $r .$ \n",
        "\n",
        "* Die Begriffe $_{n}$ Kugel\" bzw. Sph√§re\" sind dabei sehr allgemein zu sehen - beispielsweise kann eine Normkugel auch Ecken und Kanten besitzen - und **fallen nur im Spezialfall der euklidischen Vektornorm mit dem aus der Geometrie bekannten Kugelbegriff zusammen**. \n",
        "\n",
        "* W√§hlt man in der Definition $x_{0}=0$ und $r=1,$ so nennt man die entstehenden Mengen Einheitskugel bzw. Einheitssph√§re. \n",
        "\n",
        "* Jede Normkugel bzw. Normsph√§re entsteht aus der entsprechenden Einheitskugel\n",
        "bzw. Einheitssph√§re durch Skalierung mit dem Faktor $r$ und Translation um den Vektor $x_{0}$. \n",
        "\n",
        "* Ein Vektor der Einheitssph√§re hei√üt Einheitsvektor; zu jedem Vektor $x \\neq 0$ erh√§lt man durch Normierung $\\frac{x}{\\|x\\|}$ den zugeh√∂rigen Einheitsvektor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf2dS7qAxmxu",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Norm_(Mathematik)#Normkugeln"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsTnah-j5XPW",
        "colab_type": "text"
      },
      "source": [
        "**Die wichtigsten Verallgemeinerungen der Euklidischen Norm:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRax0LTq5PpT",
        "colab_type": "text"
      },
      "source": [
        "$\\ell^{2}-$ Norm (**Folgenraum**)\n",
        "\n",
        "* Die $\\ell^{2}-$ Norm ist die Verallgemeinerung der euklidischen Norm auf den [Folgenraum](https://de.m.wikipedia.org/wiki/Folgenraum) $\\ell^{2}$ der quadratisch summierbaren Folgen $\\left(a_{n}\\right)_{n} \\in \\mathbb{K}^{\\mathrm{N}} .$ Hierbei wird lediglich die endliche Summe durch eine unendliche ersetzt und die $\\ell^{2}$ -Norm ist dann gegeben als\n",
        "\n",
        "> $\\left\\|\\left(a_{n}\\right)\\right\\|_{\\ell^{2}}=\\left(\\sum_{n=1}^{\\infty}\\left|a_{n}\\right|^{2}\\right)^{1 / 2}$\n",
        "\n",
        "* Die ‚Ñì-p -R√§ume sind ein Spezialfall der allgemeineren Lp-R√§ume, wenn man das Z√§hlma√ü auf dem Raum N betrachtet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Peq0MPwB6WKs",
        "colab_type": "text"
      },
      "source": [
        "$L^{2}-$ Norm (**Funktionenraum**)\n",
        "\n",
        "* Weiter kann die euklidische Norm auf den [Funktionenraum](https://de.m.wikipedia.org/wiki/Funktionenraum) $L^{2}(\\Omega)$ der auf einer Menge $\\Omega$ quadratisch integrierbaren Funktionen verallgemeinert werden, was in zwei Schritten geschieht. Zun√§chst wird die $\\mathcal{L}^{2}$ Norm einer quadratisch Lebesgue-integrierbaren Funktion $f: \\Omega \\rightarrow \\mathbb{K}$ als\n",
        "\n",
        "> $\\|f\\|_{\\mathcal{L}^{2}(\\Omega)}=\\left(\\int_{\\Omega}|f(x)|^{2} d x\\right)^{1 / 2}$\n",
        "\n",
        "* definiert, wobei im Vergleich zur $\\ell^{2}$ -Norm lediglich die Summe durch ein Integral ersetzt wurde. Dies ist zun√§chst nur eine Halbnorm, da nicht nur die Nullfunktion, sondern auch alle Funktionen, die sich nur an einer Menge mit Lebesgue-Ma√ü Null von der Nullfunktion unterscheiden, zu Null integriert werden. Daher betrachtet man die Menge der √Ñquivalenzklassen von Funktionen $[f] \\in L^{2}(\\Omega),$ die fast √ºberall gleich sind, und erh√§lt auf diesem $L^{2}$ -Raum die $L^{2}$ -Norm durch\n",
        "\n",
        "> $\\|[f]\\|_{L^{2}(\\Omega)}=\\|f\\|_{\\mathcal{L}^{2}(\\Omega)}$\n",
        "\n",
        "* Der Raum $L^{2}(\\Omega)$ ist ein Hilbertraum mit dem Skalarprodukt zweier Funktionen\n",
        "\n",
        "> $\\langle f, g\\rangle_{L_{2}(\\Omega)}=\\int_{\\Omega} \\overline{f(x)} \\cdot g(x) d x$\n",
        "\n",
        "* Er l√§sst sich von dem Lebesgue-Ma√ü auch auf allgemeine Ma√üe verallgemeinern."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU32us9ZQouN",
        "colab_type": "text"
      },
      "source": [
        "### **Von der p‚àû-Norm (Maximumsnorm) zu L‚àû-Norm**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwOcv6tLTkxl",
        "colab_type": "text"
      },
      "source": [
        "#### **Maximumsnorm (Unendlich-Norm)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwl3Y9ZtTUDj",
        "colab_type": "text"
      },
      "source": [
        "* Die Maximumsnorm, Maximumnorm oder Tschebyschew-Norm ist eine spezielle Norm f√ºr Funktionen beziehungsweise f√ºr Vektoren oder Matrizen. Sie ist ein Spezialfall der [Supremumsnorm](https://de.m.wikipedia.org/wiki/Supremumsnorm).\n",
        "\n",
        "* Anschaulich gesprochen ist der aus der Maximumsnorm abgeleitete Abstand immer dann relevant, wenn man sich in einem mehrdimensionalen Raum in alle Dimensionen gleichzeitig und unabh√§ngig voneinander gleich schnell bewegen kann. (zB Rochade beim Schach)\n",
        "\n",
        "* Allgemeiner kann die Maximumsnorm benutzt werden, um zu bestimmen, wie schnell man sich in einem zwei- oder dreidimensionalen Raum bewegen kann, wenn angenommen wird, dass die Bewegungen in x-, y- (und z-)Richtung unabh√§ngig, gleichzeitig und mit gleicher Geschwindigkeit erfolgen.\n",
        "\n",
        "\n",
        "* Noch allgemeiner kann man ein System betrachten, dessen Zustand durch n unabh√§ngige Parameter bestimmt wird. An allen Parametern k√∂nnen gleichzeitig und ohne gegenseitige Beeinflussung √Ñnderungen vorgenommen werden. Dann ‚Äûmisst‚Äú die Maximumsnorm in Rn die Zeit, die man ben√∂tigt, um das System von einem Zustand in einen anderen zu √ºberf√ºhren. Voraussetzung hierf√ºr ist allerdings, dass man die Parameter so normiert hat, dass gleiche Abst√§nde zwischen den Werten auch gleichen √Ñnderungszeiten entsprechen. Andernfalls m√ºsste man eine gewichtete Version der Maximumsnorm verwenden, die die unterschiedlichen √Ñnderungsgeschwindigkeiten der Parameter ber√ºcksichtigt.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3CFgJHJVYZO",
        "colab_type": "text"
      },
      "source": [
        "F√ºr einen Vektor $x=\\left(x_{1}, \\ldots, x_{n}\\right) \\in \\mathbb{R}^{n}$ nennt man\n",
        "\n",
        "> $\\|x\\|_{\\max }:=\\max \\left(\\left|x_{1}\\right|, \\ldots,\\left|x_{n}\\right|\\right)$ \n",
        "\n",
        "die Maximumsnorm von x. \n",
        "\n",
        "* Die **Maximumsnorm kann auch als Grenzfall der $p$ -Normen** $\\|x\\|_{p}:=\\left(\\sum_{i=1}^{n}\\left|x_{i}\\right|^{p}\\right)^{1 / p}$ aufgefasst werden. L√§sst man $p$ gegen unendlich laufen, so erh√§lt man\n",
        "aus der $p$ -Norm die Maximumsnorm.\n",
        "\n",
        "* **Aus diesem Grund wird die Maximumsnorm f√ºr Vektoren auch als $\\infty$ -Norm (Unendlich-Norm) bezeichnet.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ar8qLNfnCi8_",
        "colab_type": "text"
      },
      "source": [
        "F√ºr den Grenzwert p‚Üí ‚àû erh√§lt man die ‚àû-Norm (Unendlich-Norm), die oft auch zu den p-Normen gez√§hlt wird. Sie wird auch **Maximumsnorm oder Tschebyschow-Norm** genannt und ist definiert durch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioRBlq9ICFf6",
        "colab_type": "text"
      },
      "source": [
        "> $\\|x\\|_{\\infty}=\\max _{i=1, \\ldots, n}\\left|x_{i}\\right|$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hpZp3hzCXku",
        "colab_type": "text"
      },
      "source": [
        "Dass die Maximumsnorm tats√§chlich als Grenzwert der $p$ -Normen f√ºr $p \\rightarrow \\infty$ entsteht, folgt f√ºr $x \\neq 0$\n",
        "aus\n",
        "\n",
        "> $\\lim _{p \\rightarrow \\infty}\\|x\\|_{p}=\\lim _{p \\rightarrow \\infty}\\left(\\sum_{i=1}^{n}\\left|x_{i}\\right|^{p}\\right)^{1 / p}=\\|x\\|_{\\infty} \\cdot \\lim _{p \\rightarrow \\infty}\\left(\\sum_{i=1}^{n}\\left(\\frac{\\left|x_{i}\\right|}{\\|x\\|_{\\infty}}\\right)^{p}\\right)^{1 / p}=\\|x\\|_{\\infty} \\cdot \\lim _{p \\rightarrow \\infty} S^{1 / p}=\\|x\\|_{\\infty}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIA4-xLTSKoB",
        "colab_type": "text"
      },
      "source": [
        "* For a real number p ‚â• 1, the p-norm or Lp-norm of x is defined by\n",
        "\n",
        "> $\\|x\\|_{p}=\\left(\\left|x_{1}\\right|^{p}+\\left|x_{2}\\right|^{p}+\\cdots+\\left|x_{n}\\right|^{p}\\right)^{1 / p}$\n",
        "\n",
        "* The absolute value bars are unnecessary when p is a rational number and, in reduced form, has an even numerator.\n",
        "\n",
        "* The L‚àû-norm or maximum norm (or uniform norm) is the limit of the Lp-norms for p ‚Üí ‚àû. It turns out that this limit is equivalent to the following definition:\n",
        "\n",
        "> $\\|x\\|_{\\infty}=\\max \\left\\{\\left|x_{1}\\right|,\\left|x_{2}\\right|, \\ldots,\\left|x_{n}\\right|\\right\\}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbrnlkWOBNEE",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Maximumsnorm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KesWFfaTmuu",
        "colab_type": "text"
      },
      "source": [
        "#### **Supremumsnorm**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0mN6eYZT6rC",
        "colab_type": "text"
      },
      "source": [
        "* Im Gegensatz zur Maximumsnorm wird die Supremumsnorm $\\|f\\|_{\\text {sup }}:=\\sup _{t \\in X}|f(t)|$ nicht f√ºr stetige, sondern f√ºr beschr√§nkte Funktionen $f$ definiert. \n",
        "\n",
        "* In diesem Fall ist es nicht notwendig, dass $X$ kompakt ist; $X$ kann eine beliebige Menge sein. Da stetige Funktionen auf kompakten R√§umen beschr√§nkt sind, ist die Maximumsnorm ein Spezialfall der Supremumsnorm.\n",
        "\n",
        "* Die Supremumsnorm (auch Unendlich-Norm genannt) ist in der Mathematik eine Norm auf dem Funktionenraum der beschr√§nkten Funktionen. Im einfachsten Fall einer reell- oder komplexwertigen beschr√§nkten Funktion ist die Supremumsnorm das Supremum der Betr√§ge der Funktionswerte. Allgemeiner betrachtet man Funktionen, deren Zielmenge ein normierter Raum ist, und die Supremumsnorm ist dann das Supremum der Normen der Funktionswerte. F√ºr stetige Funktionen auf einer kompakten Menge ist die Maximumsnorm ein wichtiger Spezialfall der Supremumsnorm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrQFlg6EWE26",
        "colab_type": "text"
      },
      "source": [
        "![alternativer Text](https://upload.wikimedia.org/wikipedia/commons/thumb/6/66/Graf_arctg.svg/260px-Graf_arctg.svg.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9WdCWwbWJVf",
        "colab_type": "text"
      },
      "source": [
        "*Die Supremumsnorm der reellen Arkustangens-Funktion ist œÄ/2. Auch wenn die Funktion diesen Wert betragsm√§√üig nirgendwo annimmt, so bildet er dennoch die kleinste obere Schranke.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIHI-jmUWwUr",
        "colab_type": "text"
      },
      "source": [
        "Supremumsnorm vs Maximumsnorm:\n",
        "\n",
        "* So ist etwa die **Supremumsnorm** der linearen Funktion $f(x)=x$ in diesem Intervall gleich $1 .$ Die Funktion nimmt diesen Wert zwar innerhalb des Intervalls nicht an, kommt inm jedoch beliebig nahe. \n",
        "\n",
        "* W√§hlt man stattdessen das abgeschlossene Einheitsintervall $M=[0,1]$, dann wird der Wert 1 angenommen und die Supremumsnorm entspricht der **Maximumsnorm**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDKcUEhwTZKC",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Supremumsnorm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3OOjvbpXuEt",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Wesentliches_Supremum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVuurd_GTqys",
        "colab_type": "text"
      },
      "source": [
        "#### **L-Infinity**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4x8mIupEplw",
        "colab_type": "text"
      },
      "source": [
        "* The vector space ‚Ñì‚àû is a **sequence space** (Folgenraum) whose elements are the bounded sequences. The vector space operations, addition and scalar multiplication, are applied coordinate by coordinate. \n",
        "\n",
        "* L‚àû is a **function space** (Funktionenraum). Its elements are the essentially bounded measurable functions. More precisely, L‚àû is defined based on an underlying measure space, (S, Œ£, Œº). Start with the set of all measurable functions from S to R which are essentially bounded, i.e. bounded up to a set of measure zero. Two such functions are identified if they are equal almost everywhere. Denote the resulting set by L‚àû(S, Œº)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIMWHQgyXYiA",
        "colab_type": "text"
      },
      "source": [
        "* $\\ell^{\\infty},$ the (real or complex) vector space of bounded sequences with the **[supremum norm](https://de.m.wikipedia.org/wiki/Supremumsnorm)**, and $L^{\\infty}=L^{\\infty}(X, \\Sigma, \\mu)$, the vector space of essentially bounded measurable functions with the **[essential supremum norm](https://de.m.wikipedia.org/wiki/Wesentliches_Supremum)**, are two closely related Banach spaces. \n",
        "\n",
        "* In fact the former is a special case of the latter. As a Banach space they are the continuous dual of the Banach spaces $\\ell_{1}$ of absolutely summable sequences, and $L^{1}=L^{1}(X, \\Sigma, \\mu)$ of absolutely integrable measurable functions (if the measure space fulfills the conditions of being localizable and therefore\n",
        "semifinite). \n",
        "\n",
        "* Pointwise multiplication gives them the structure of a Banach algebra, and in fact they are the standard examples of abelian Von Neumann algebras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHSE1UbcYFEP",
        "colab_type": "text"
      },
      "source": [
        "**The sequence space (Folgenraum) is a special case of the function space (Funktionenraum): $\\ell_{\\infty}=L_{\\infty}(\\mathbb{N})$ where the natural numbers are equipped with the counting measure.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trPSIZzFS6uw",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/L-infinity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHE_58TCK5mP",
        "colab_type": "text"
      },
      "source": [
        "### **Von den L<sup>p</sup> Normen zu den L<sup>p</sup> Spaces**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYn1j_U9lfis",
        "colab_type": "text"
      },
      "source": [
        "Der **normierte Vektorraum** $L^{p}$ ist [vollst√§ndig](https://de.m.wikipedia.org/wiki/Vollst√§ndiger_Raum) und damit ein [Banachraum](https://de.m.wikipedia.org/wiki/Banachraum), die Norm $\\|\\cdot\\|_{L} p$ wird **$L^{p}$ Norm** genannt.\n",
        "\n",
        "Auch wenn man von sogenannten $L^{p}$ -Funktionen spricht, handelt es sich dabei um die gesamte √Ñquivalenzklasse einer klassischen Funktion. Allerdings liegen im Falle des Lebesgue-Ma√ües auf dem $\\mathbb{R}^{n}$ zwei verschiedene stetige Funktionen nie in der gleichen √Ñquivalenzklasse, so dass der $L^{p}$\n",
        "-Begriff eine nat√ºrliche Erweiterung des Begriffs stetiger Funktionen darstellt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S725bXUeKYmW",
        "colab_type": "text"
      },
      "source": [
        "* The Lp spaces are [function spaces](https://en.m.wikipedia.org/wiki/Function_space) defined using a natural **generalization of the p-norm for finite-dimensional vector spaces**. They are sometimes called **Lebesgue spaces**.\n",
        "\n",
        "* A normed vector space is automatically a metric space, by defining the metric in terms of the norm in the natural way. But a metric space may have no algebraic (vector) structure ‚Äî i.e., it may not be a vector space ‚Äî so the concept of a **metric space is a generalization of the concept of a normed vector space**.\n",
        "\n",
        "* Lp spaces form an important class of [Banach spaces](https://en.m.wikipedia.org/wiki/Banach_space) in functional analysis, and of topological vector spaces.\n",
        "\n",
        "* In statistics, measures of central tendency and statistical dispersion, such as the mean, median, and standard deviation, are defined in terms of Lp metrics, and measures of central tendency can be characterized as [solutions to variational problems](https://en.m.wikipedia.org/wiki/Central_tendency#Solutions_to_variational_problems)\n",
        "\n",
        "* An Lp space may be defined as a space of measurable functions for which the p-th power of the absolute value is Lebesgue integrable, where functions which agree almost everywhere are identified. \n",
        "\n",
        "* More generally, let 1 ‚â§ p < ‚àû and (S, Œ£, Œº) be a [measure space](https://en.m.wikipedia.org/wiki/Measure_space). Consider the set of all measurable functions from S to C or R whose absolute value raised to the p-th power has a finite integral, or equivalently, that\n",
        "\n",
        "> $\\|f\\|_{p} \\equiv\\left(\\int_{S}|f|^{p} \\mathrm{d} \\mu\\right)^{1 / p}<\\infty$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdACuRMye29o",
        "colab_type": "text"
      },
      "source": [
        "The **space Lp for 0 < p < 1 is an [F-space](https://en.m.wikipedia.org/wiki/F-space)**: it admits a complete translation-invariant metric with respect to which the vector space operations are continuous. It is also locally bounded, much like the case p ‚â• 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikJhQfzmlAP1",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Lp-Raum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI1toWT6AZet",
        "colab_type": "text"
      },
      "source": [
        "### **Exkurs: Sequence Space (Folgenraum) vs Function Space (Funktionenraum)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEBy-NHOAgJ_",
        "colab_type": "text"
      },
      "source": [
        "* Ein Folgenraum ist ein in der Mathematik betrachteter Vektorraum, dessen Elemente Zahlenfolgen sind. Viele in der Funktionalanalysis auftretende Vektorr√§ume sind Folgenr√§ume oder k√∂nnen durch solche repr√§sentiert werden. Zu den Beispielen z√§hlen u. a. die wichtigen R√§ume wie ‚Ñì‚àû aller beschr√§nkten Folgen oder c0 aller gegen 0 konvergenten Folgen.\n",
        "\n",
        "* **Werden Normen bzw. Systeme von Normen oder Halbnormen auf Folgenr√§umen definiert, erh√§lt man normierte R√§ume bzw. lokalkonvexe R√§ume.**\n",
        "\n",
        "* A **sequence space** (Folgenraum) is a vector space whose elements are infinite sequences of real or complex numbers. \n",
        "\n",
        "* Equivalently, it is a **function space** (Funktionenraum) whose elements are functions from the natural numbers to the field K of real or complex numbers. \n",
        "\n",
        "* The set of all such functions is naturally identified with the set of all possible infinite sequences with elements in K, and can be turned into a vector space under the operations of pointwise addition of functions and pointwise scalar multiplication. All sequence spaces are linear subspaces of this space. Sequence spaces are typically equipped with a norm, or at least the structure of a topological vector space.\n",
        "\n",
        "* The **most important sequence spaces in analysis are the ‚Ñìp spaces**, consisting of the p-power summable sequences, with the p-norm. These are special cases of Lp spaces for the counting measure on the set of natural numbers. \n",
        "\n",
        "* Other important classes of sequences like convergent sequences or null sequences (Nullfolgen) form sequence spaces, respectively denoted c and c0, with the sup norm. Any sequence space can also be equipped with the topology of pointwise convergence, under which it becomes a special kind of Fr√©chet space called FK-space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O9pC39wDsQ4",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Folgenraum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bmbh-1CIDuKZ",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Funktionenraum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oaxbCPG0PUB",
        "colab_type": "text"
      },
      "source": [
        "### **Weitere Normen: Matrixnorm**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_AGvxsw-HqD",
        "colab_type": "text"
      },
      "source": [
        "* Eine Matrixnorm ist in der Mathematik eine Norm auf dem Vektorraum der reellen oder komplexen Matrizen. \n",
        "\n",
        "* Neben den drei Normaxiomen Definitheit, absolute Homogenit√§t und Subadditivit√§t wird bei Matrixnormen teilweise die Submultiplikativit√§t als vierte definierende Eigenschaft gefordert. Submultiplikative Matrixnormen besitzen einige n√ºtzliche Eigenschaften, so ist beispielsweise der Spektralradius einer quadratischen Matrix, also der Betrag des betragsgr√∂√üten Eigenwerts, niemals gr√∂√üer als ihre Matrixnorm.\n",
        "\n",
        "* Es gibt mehrere M√∂glichkeiten, Matrixnormen zu definieren, unter anderem direkt √ºber eine Vektornorm, als Operatornorm oder √ºber die Singul√§rwerte der Matrix. Matrixnormen werden insbesondere in der linearen Algebra und der numerischen Mathematik verwendet.\n",
        "\n",
        "Wichtige Matrixnormen:\n",
        "* √úber Vektornormen definierte Matrixnormen\n",
        "* √úber Operatornormen definierte Matrixnormen\n",
        "* √úber Singul√§rwerte definierte Matrixnormen\n",
        "\n",
        "https://de.m.wikipedia.org/wiki/Matrixnorm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7u1GiAGVvzL",
        "colab_type": "text"
      },
      "source": [
        "## **Metric Spaces (Distances & Metrics)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVZMwFV4sD33",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Metrischer_Raum#Einordnung_in_die_Hierarchie_mathematischer_Strukturen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbxCak1TsHDa",
        "colab_type": "text"
      },
      "source": [
        "Metriken geben einem Raum eine globale und eine lokale mathematische Struktur. Die globale Struktur kommt in geometrischen Eigenschaften wie der Kongruenz von Figuren zum Ausdruck. Die lokale metrische Struktur, also die Definition kleiner Abst√§nde, erm√∂glicht unter bestimmten zus√§tzlichen Voraussetzungen die Einf√ºhrung von Differentialoperationen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2VqyxFgIRLt",
        "colab_type": "text"
      },
      "source": [
        "### **From Divergences to Metric Spaces**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfT-0QZZm8VW",
        "colab_type": "text"
      },
      "source": [
        "#### **Properties**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HScpxU3gCkB",
        "colab_type": "text"
      },
      "source": [
        "1. $d(x, y) \\geq 0 \\quad$ (**non-negativity**)\n",
        "\n",
        "2. $d(x, y)=0$ if and only if $x=y$ (**identity of indiscernibles**. Note that condition 1 and 2 together produce **positive definiteness**)\n",
        "\n",
        "3. $d(x, y)=d(y, x)$ (**symmetry**)\n",
        "\n",
        "4. $d(x, z) \\leq d(x, y)+d(y, z)$ (**subadditivity / triangle inequality**)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGoqrlNKgEo8",
        "colab_type": "text"
      },
      "source": [
        "* **Divergence** fullfills property of positive definiteness (1 + 2)\n",
        "\n",
        "* **Distance** fullfills property of positive definiteness and symmetrie (1 + 2+ 3)\n",
        "\n",
        "* **Metric** fullfills property of positive definiteness, symmetrie and triangle inequality (1 + 2 + 3 + 4)\n",
        "\n",
        "* Metric Space: Together with the set, a metric makes up a metric space.\n",
        "\n",
        "* (*Jede Norm induziert eine Metrik, aber nicht jede Metrik wird durch eine Norm induziert*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbyK2erJfiMZ",
        "colab_type": "text"
      },
      "source": [
        "Given a set $X$ of points, a distance function on $X$ is a map $d: X \\times X \\rightarrow \\mathbb{R}_{+}$ that is symmetric, and satisfies $d(i, i)=0$ for all $i \\in X .$ \n",
        "\n",
        "* Eine Metrik (auch Abstandsfunktion) ist eine Funktion, die je zwei Elementen des Raums einen nicht negativen reellen Wert zuordnet, der als Abstand der beiden Elemente voneinander aufgefasst werden kann. \n",
        "\n",
        "* The metric is a function that defines a concept of distance between any two members of the set, which are usually called points. The metric satisfies a few simple properties.\n",
        "\n",
        "* Unter einem [metrischen Raum](https://de.m.wikipedia.org/wiki/Metrischer_Raum) (metric space) versteht man in der Mathematik eine Menge, auf der eine Metrik definiert ist. \n",
        "\n",
        "* A metric on a space induces topological properties like open and closed sets, which lead to the study of more abstract topological spaces. Der Begriff ‚Äûtopologischer Raum‚Äú verallgemeinert den Begriff ‚Äûmetrischer Raum‚Äú: Jeder metrische Raum ist ein topologischer Raum mit der Topologie, die durch die Metrik induziert wird (siehe dazu [Umgebung](https://de.m.wikipedia.org/wiki/Umgebung_(Mathematik))). Jeder metrische Raum ist ein [Hausdorff-Raum](https://de.m.wikipedia.org/wiki/Hausdorff-Raum)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_8BD2qlqkKE",
        "colab_type": "text"
      },
      "source": [
        "Falls die Funktion d zus√§tzlich die Dreiecksungleichung erf√ºllt, ist sie eine Metrik. H√§ufig wird auch eine Metrik als Distanzfunktion bezeichnet.\n",
        "\n",
        "https://de.m.wikipedia.org/wiki/Distanzfunktion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1zsesz3sQZl",
        "colab_type": "text"
      },
      "source": [
        "Eine [Isometrie](https://de.m.wikipedia.org/wiki/Isometrie) ist eine Abbildung, die zwei metrische R√§ume aufeinander abbildet und dabei die Metrik ‚Äì also die Abst√§nde zwischen je zwei Punkten ‚Äì erh√§lt. ps: [Isometrische Isomorphie](https://de.m.wikipedia.org/wiki/Isometrische_Isomorphie) beschreibt in der Funktionalanalysis einen Zusammenhang zwischen zwei unterschiedlichen R√§umen, die geometrisch identisch sind."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7d7_An6wMZW",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Continuous_function#Continuous_functions_between_metric_spaces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMMYN7ReV1TC",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Metric_space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A0RiFz6sHZ-",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Distance#General_metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDrk6VPEtOU2",
        "colab_type": "text"
      },
      "source": [
        "#### **Exkurs: Norms vs Metrics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGuci0L-l6c3",
        "colab_type": "text"
      },
      "source": [
        "**Instead of distance between points, a norm gives us the length of a vector, as measured from the origin.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pdUxKjtgFkR",
        "colab_type": "text"
      },
      "source": [
        "Metrics and norms are related, and they can both convey a notion of distance.\n",
        "\n",
        "If we have a set ùëã, then we say that the function  ùëë:ùëã√óùëã‚Üí‚Ñù‚â•0 is a metric on ùëã if it satisfies the following for all points  ùë•,ùë¶,ùëß‚ààùëã: \n",
        "\n",
        ">  ùëë(ùë•,ùë¶)=0‚üπùë•=ùë¶\n",
        "\n",
        "> ùëë(ùë•,ùë¶)=ùëë(ùë¶,ùë•)\n",
        "\n",
        "> ùëë(ùë•,ùë¶)‚â§ùëë(ùë•,ùëß)+ùëë(ùë¶,ùëß).\n",
        "\n",
        "* **We call the function ùëë a metric or distance function. (Without the triangle inequality it's just a distance, but not a metric!)**\n",
        "\n",
        "* What do these properties say though? First, if the distance between two points is 0, then they are actually the same point. Second, the distance doesn't change if you swap where you start and end. The third property is called the triangle inequality, and is motivated by the corresponding property for real numbers.\n",
        "\n",
        "* The **problem with a metric is that sometimes, they can be too general**.\n",
        "\n",
        "* For example, take  ùëã=‚Ñö  and let  ùëë(ùë•,ùë¶)=0 if  ùë•=ùë¶, and  ùëë(ùë•,ùë¶)=1 if  ùë•‚â†ùë¶. I'll let you check it is indeed a metric. This metric sucks. I mean, **it doesn't give you any geometrical interpretation of ‚Äúdistance‚Äù,** and our metric space (‚Ñö,ùëë) is very hard to visualize, even though ‚Ñö is a nice and familiar set. On a graph (the combinatorial object) this metric may be useful, but I digress.\n",
        "\n",
        "* On the other hand, **a norm must be defined on a vector space**, which inherently have a lot of structure!\n",
        "\n",
        "* Let  ùëâ be a vector space over the field  ùëò. A norm is a function  ‚Äñ‚Ä¢‚Äñ:ùëâ‚Üí‚Ñù‚â•0 that satsfies the following for all ùúÜ‚ààùëò and ùë•,ùë¶‚ààùëâ:\n",
        "\n",
        "* ‚Äñùë•‚Äñ=0‚üπùë•=0\n",
        "* ‚ÄñùúÜùë•‚Äñ=|ùúÜ|‚Äñùë•‚Äñ\n",
        "* ‚Äñùë•+ùë¶‚Äñ‚â§‚Äñùë•‚Äñ+‚Äñùë¶‚Äñ\n",
        " \n",
        "* <u>**Instead of distance between points, a norm gives us the length of a vector, as measured from the origin**</u>. Property 3 is also called the triangle inequality, but now it has a nice geometric interpretation (unlike in a general metric space). Also you can give necessary and sufficient conditions on when the triangle inequality is actually an equailty. Not so in a metric space.\n",
        "\n",
        "* It is easy to see that **a norm is a metric on  ùëâ, because length is the same as ‚Äúdistance from 0.‚Äù** To check, simply replace  ùë• by  ùë£‚àíùë§ in the definition of a norm and say  ‚Äñùë£‚àíùë§‚Äñ=ùëë(ùë£,ùë§). (Note that ùë£‚àíùë§‚ààùëâ because  ùëâ is a linear space, so we can take it's norm).\n",
        "\n",
        "* This does not hold conversely because we may not even have addition of elements in a general set  ùëã.\n",
        "\n",
        "* To sum up: **All norms are metrics, and normed spaces** (vector spaces with a norm) have a lot more structure than general metric spaces. Anything that holds in a metric space will also hold for a normed space. Metric spaces are more general, but can be ugly!\n",
        "\n",
        "[Source Quora](https://www.quora.com/What-is-the-difference-between-a-metric-and-a-norm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXt3-c9EhID7",
        "colab_type": "text"
      },
      "source": [
        "### **Divergences**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gD8HZ1Q1giLt",
        "colab_type": "text"
      },
      "source": [
        "#### **Divergence & 'Statistical Distance'**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqH4VD9zgjtm",
        "colab_type": "text"
      },
      "source": [
        "In statistics and information geometry, divergence or a contrast function is a function which establishes the **\"distance\" of one probability distribution to the other** on a statistical manifold. In statistics, probability theory, and information theory, **a statistical distance** quantifies the distance between two statistical objects, which can be\n",
        "\n",
        "* two random variables, or \n",
        "* two probability distributions or \n",
        "* two samples, or \n",
        "* the distance can be between an individual sample point and a population or \n",
        "* a wider sample of points.\n",
        "\n",
        "A distance between populations can be interpreted as **measuring the distance between two probability distributions** and hence they are essentially measures of distances between probability measures. \n",
        "\n",
        "* Where statistical distance measures relate to the differences between random variables, these may have statistical dependence, and hence these distances are not directly related to measures of distances between probability measures. \n",
        "\n",
        "* Again, a measure of distance between random variables may **relate to the extent of dependence between them, rather than to their individual values.**\n",
        "\n",
        "**<u>Many statistical distances are not metrics</u>** (and some types are regerred to as divergence), because they lack one or more properties of proper metrics. For example, \n",
        "\n",
        "* [pseudometrics](https://en.m.wikipedia.org/wiki/Pseudometric_space) violate the \"positive definiteness\" (alternatively, \"identity of indescernibles\") property (1 & 2 above); \n",
        "\n",
        "* [quasimetrics](https://en.m.wikipedia.org/wiki/Metric_(mathematics)#Quasimetrics) violate the symmetry property (3); and semimetrics violate the triangle inequality (4). \n",
        "\n",
        "* Statistical distances that satisfy (1) and (2) are referred to as divergences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y2GffaHgpYZ",
        "colab_type": "text"
      },
      "source": [
        "* In statistics and information geometry, there are many kinds of statistical distances, notably divergences, especially Bregman divergences and f-divergences. These include and generalize many of the notions of \"difference between two probability distributions\", and allow them to be studied geometrically, as statistical manifolds. \n",
        "\n",
        "* The **most elementary** is the **squared Euclidean distance**, which forms the basis of least squares; this is the most basic Bregman divergence (-> is this a metric then ???)\n",
        "\n",
        "* The **most important** in information theory is the relative entropy (**Kullback‚ÄìLeibler divergence**), which allows one to analogously study maximum likelihood estimation geometrically; this is the most basic f-divergence, and is also a Bregman divergence (and is the only divergence that is both). \n",
        "\n",
        "* Statistical manifolds corresponding to Bregman divergences are flat manifolds in the corresponding geometry, allowing an analog of the Pythagorean theorem (which is traditionally true for squared Euclidean distance) to be used for linear inverse problems in inference by optimization theory.\n",
        "\n",
        "* Other important statistical distances include the Mahalanobis distance, the energy distance, and many others."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_6VnI9tgsJe",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Information_geometry\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Statistical_distance\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Divergence_(statistics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15ok6ieBgYkv",
        "colab_type": "text"
      },
      "source": [
        "#### **Meaning of 'no symmetry' in divergences**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFglF2QTgaEc",
        "colab_type": "text"
      },
      "source": [
        "* The Kullback-Leibler divergence is not symmetric. Roughly speaking, it's because you should think of the two arguments of the KL divergence as different kinds of things: the first argument is empirical data, and the second argument is a model you're comparing the data to. \n",
        "\n",
        "* Take a bunch of independent random variables $X_{1}, \\ldots, X_{n}$ whose possible values lie in a finite set.* Say these variables are identically distributed, with $\\operatorname{Pr}\\left(X_{i}=x\\right)=p_{x}$. Let $F_{n, x}$ be the number of variables whose values are equal to $x$. The list $F_{n}$ is a random variable, often called the \"empirical frequency distribution\" of the $X_{i} .$ What does $F_{n}$ look like when $n$ is very large?\n",
        "\n",
        "* More specifically, let's try to estimate the probabilities of the possible values of $F_{n} .$ since the set of possible values is different for different $n$, take a sequence of frequency distributions $f_{1}, f_{2}, f_{3}, \\ldots$ approaching a fixed frequency distribution $f$. It turns out $^{* *}$ that\n",
        "\n",
        "> $\\lim _{n \\rightarrow \\infty} \\frac{1}{n} \\ln \\operatorname{Pr}\\left(F_{n}=f_{n}\\right)=-\\mathrm{KL}(f, p)$ \n",
        "\n",
        "* In other words, the Kullback-Leibler divergence of $f$ from $p$ lets you estimate the probability of getting an empirical frequency distribution close to $f$ from a large number of independent random variables with distribution $p$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEE5LAAygcf-",
        "colab_type": "text"
      },
      "source": [
        "Excellent article \"Information Theory, Relative Entropy and Statistics,\" by [Fran√ßois Bavaud](https://link.springer.com/chapter/10.1007/978-3-642-00659-3_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1geLcP8Pgut9",
        "colab_type": "text"
      },
      "source": [
        "List of Distances Types\n",
        "\n",
        "'braycurtis': hdbscan.dist_metrics.BrayCurtisDistance\n",
        "\n",
        "'canberra': hdbscan.dist_metrics.CanberraDistance\n",
        "\n",
        "'chebyshev': hdbscan.dist_metrics.ChebyshevDistance\n",
        "\n",
        "'cityblock': hdbscan.dist_metrics.ManhattanDistance\n",
        "\n",
        "'dice': hdbscan.dist_metrics.DiceDistance\n",
        "\n",
        "'euclidean': hdbscan.dist_metrics.EuclideanDistance\n",
        "\n",
        "'hamming': hdbscan.dist_metrics.HammingDistance\n",
        "\n",
        "'haversine': hdbscan.dist_metrics.HaversineDistance\n",
        "\n",
        "'infinity': hdbscan.dist_metrics.ChebyshevDistance\n",
        "\n",
        "'jaccard': hdbscan.dist_metrics.JaccardDistance\n",
        "\n",
        "'kulsinski': hdbscan.dist_metrics.KulsinskiDistance\n",
        "\n",
        "'l1': hdbscan.dist_metrics.ManhattanDistance\n",
        "\n",
        "'l2': hdbscan.dist_metrics.EuclideanDistance\n",
        "\n",
        "'mahalanobis': hdbscan.dist_metrics.MahalanobisDistance\n",
        "\n",
        "'manhattan': hdbscan.dist_metrics.ManhattanDistance\n",
        "\n",
        "'matching': hdbscan.dist_metrics.MatchingDistance\n",
        "\n",
        "'minkowski': hdbscan.dist_metrics.MinkowskiDistance\n",
        "\n",
        "'p': hdbscan.dist_metrics.MinkowskiDistance\n",
        "\n",
        "'pyfunc': hdbscan.dist_metrics.PyFuncDistance\n",
        "\n",
        "'rogerstanimoto': hdbscan.dist_metrics.RogersTanimotoDistance\n",
        "\n",
        "'russellrao': hdbscan.dist_metrics.RussellRaoDistance\n",
        "\n",
        "'seuclidean': hdbscan.dist_metrics.SEuclideanDistance\n",
        "\n",
        "'sokalmichener': hdbscan.dist_metrics.SokalMichenerDistance\n",
        "\n",
        "'sokalsneath': hdbscan.dist_metrics.SokalSneathDistance\n",
        "\n",
        "'wminkowski': hdbscan.dist_metrics.WMinkowskiDistance\n",
        "\n",
        "https://hdbscan.readthedocs.io/en/latest/basic_hdbscan.html\n",
        "\n",
        "https://reference.wolfram.com/language/guide/DistanceAndSimilarityMeasures.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAdXAeihnHMA",
        "colab_type": "text"
      },
      "source": [
        "#### **Types of Divergences**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSRliOMMiHC-",
        "colab_type": "text"
      },
      "source": [
        "**Jensen‚ÄìShannon divergence**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AgQmDiLiJW_",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Jensen‚ÄìShannon_divergence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhwL39dIoAR5",
        "colab_type": "text"
      },
      "source": [
        "**Squared Euclidean Distance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mHVqq2toEeh",
        "colab_type": "text"
      },
      "source": [
        "* Squared Euclidean distance is of central importance in estimating parameters of statistical models, where it is used in the method of least squares, a standard approach to regression analysis. \n",
        "\n",
        "* The corresponding loss function is the squared error loss (SEL), and places progressively greater weight on larger errors. The corresponding risk function (expected loss) is mean squared error (MSE).\n",
        "\n",
        "* **Squared Euclidean distance is not a metric**, as it does not satisfy the triangle inequality. However, **it is a more general notion of distance, namely a divergence** (specifically a Bregman divergence), and can be used as a statistical distance. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjoet-ldoMGv",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Euclidean_distance#Squared_Euclidean_distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HN2Dn3F0iAzD",
        "colab_type": "text"
      },
      "source": [
        "**Kullback‚ÄìLeibler divergence**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OWsTyvziEce",
        "colab_type": "text"
      },
      "source": [
        "The only divergence that is both an f-divergence and a Bregman divergence is the Kullback‚ÄìLeibler divergence\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Kullback‚ÄìLeibler_divergence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmZFI8hdhy1u",
        "colab_type": "text"
      },
      "source": [
        "**f-Divergence**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9smhem9wh0x8",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/F-divergence\n",
        "\n",
        "The Hellinger distance is a type of f-divergence\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Hellinger_distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-59nC3Yih3Gm",
        "colab_type": "text"
      },
      "source": [
        "**Bregman Divergence**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXaFiel6h7Fl",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Bregman_divergence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnDfoUM_h5VG",
        "colab_type": "text"
      },
      "source": [
        "The squared Euclidean divergence is a Bregman divergence (corresponding to the function x<sup>2</sup>, but not an f-divergence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vvhq-zZ2h9Ae",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Euclidean_distance#Squared_Euclidean_distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO5uuQMehFZD",
        "colab_type": "text"
      },
      "source": [
        "### **Distance & Similarity Measure**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXNI2l-ru6OO",
        "colab_type": "text"
      },
      "source": [
        "#### **Distance Measure vs Similarity Measure**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaujIQ5EgM4q",
        "colab_type": "text"
      },
      "source": [
        "* **√Ñhnlichkeitsma√üe** werden f√ºr nominal oder ordinal skalierte Variablen genutzt\n",
        "\n",
        "* **Distanzma√üe** werden f√ºr metrisch skalierte Variablen (d. h. f√ºr Intervall- und Verh√§ltnisskala) genutzt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdhCXyrkgLB0",
        "colab_type": "text"
      },
      "source": [
        "In der Statistik, insbesondere der Multivariaten Statistik, interessiert man sich f√ºr die Messung der √Ñhnlichkeit zwischen verschiedenen Objekten und definiert dazu √Ñhnlichkeits- und Distanzma√üe. **Es handelt sich dabei nicht um Ma√üe im mathematischen Sinn**, der Begriff bezieht sich ausschlie√ülich auf die Messung einer bestimmten Gr√∂√üe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ez_pHYiXgPcu",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/√Ñhnlichkeitsanalyse\n",
        "\n",
        "https://de.m.wikipedia.org/wiki/Distanzfunktion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu_3BJSrgnoi",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Distance_(graph_theory)\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "158GOppauyjW",
        "colab_type": "text"
      },
      "source": [
        "**Similarity Learning & Similarity Measures**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3kmaTK4wLuh",
        "colab_type": "text"
      },
      "source": [
        "√Ñhnlichkeitsma√üe werden f√ºr nominal oder ordinal skalierte Variablen genutzt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VyoAh5jw5zd",
        "colab_type": "text"
      },
      "source": [
        "**Similarity Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3kMumcau1jK",
        "colab_type": "text"
      },
      "source": [
        "Similarity learning is an area of supervised machine learning in artificial intelligence. It is closely related to regression and classification, but the goal is to learn a similarity function that measures how similar or related two objects are. It has applications in ranking, in recommendation systems, visual identity tracking, face verification, and speaker verification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbKu0ozEiQxS",
        "colab_type": "text"
      },
      "source": [
        "other approaches to learn a distance metric from examples.\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Similarity_learning\n",
        "\n",
        "Triplet Loss (a loss function for machine learning algorithms) is often used for learning similarity for the purpose of learning embeddings, like word embeddings and even thought vectors, and metric learning.\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Triplet_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IL8yx8TPwzxd",
        "colab_type": "text"
      },
      "source": [
        "**Similarity Measure**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YROdjwerw1vn",
        "colab_type": "text"
      },
      "source": [
        "* In statistics and related fields, a similarity measure or similarity function is a real-valued function that quantifies the similarity between two objects. \n",
        "\n",
        "* Although no single definition of a similarity measure exists, usually such measures are in some sense the inverse of distance metrics: they take on large values for similar objects and either zero or a negative value for very dissimilar objects.\n",
        "\n",
        "* Cosine similarity is a commonly used similarity measure for real-valued vectors, used in (among other fields) information retrieval to score the similarity of documents in the vector space model. In machine learning, common kernel functions such as the RBF kernel can be viewed as similarity functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iXAC70pwnTo",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Similarity_measure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRiPX5ymiOQB",
        "colab_type": "text"
      },
      "source": [
        "**Distance Metric Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcYq501LwPx2",
        "colab_type": "text"
      },
      "source": [
        "**Distanzma√üe** werden f√ºr metrisch skalierte Variablen (d. h. f√ºr Intervall- und Verh√§ltnisskala) genutzt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g5n2_2QuXGU",
        "colab_type": "text"
      },
      "source": [
        "Similarity learning is closely related to distance metric learning. Metric learning is the task of learning a distance function over objects. A metric or distance function has to obey four axioms: non-negativity, identity of indiscernibles, symmetry and subadditivity (or the triangle inequality). **In practice, metric learning algorithms ignore the condition of identity of indiscernibles and learn a pseudo-metric**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecLaHQ8EiXyP",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Similarity_learning#Metric_learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fW7iOU1uAvm",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AepjAni7x_g9",
        "colab_type": "text"
      },
      "source": [
        "**Exkurs**: [Distance measures](https://en.m.wikipedia.org/wiki/Distance_measures_(cosmology)) in cosmology are complicated by the [expansion of the universe](https://en.m.wikipedia.org/wiki/Expansion_of_the_universe), and by effects described by the [theory of relativity](https://en.m.wikipedia.org/wiki/Theory_of_relativity) such as [length contraction](https://en.m.wikipedia.org/wiki/Length_contraction) of moving objects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajT03d8Bzwz_",
        "colab_type": "text"
      },
      "source": [
        "#### **Types of Distance & Similarity Measures**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXBpZ1M8zNi5",
        "colab_type": "text"
      },
      "source": [
        "##### **Types of Similarity Measures**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAf4sna4hQMg",
        "colab_type": "text"
      },
      "source": [
        "**Jaccard-Koeffizient**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYu5h2eLhR-N",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Jaccard-Koeffizient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8TsNTlqxSEe",
        "colab_type": "text"
      },
      "source": [
        "**Ranking (information retrieval) (??)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDLkuNEhxWTi",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Ranking_(information_retrieval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnYACyf4xaDw",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Learning_to_rank"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhsJkHxGxizH",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Information_retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft0KCnh_xr23",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Vector_space_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZT8FPvZ3hi1N",
        "colab_type": "text"
      },
      "source": [
        "**Bhattacharyya distance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1YoJ42mx-xb",
        "colab_type": "text"
      },
      "source": [
        "* In statistics, the Bhattacharyya distance measures the similarity of two probability distributions. It is closely related to the Bhattacharyya coefficient which is a measure of the amount of overlap between two statistical samples or populations. \n",
        "\n",
        "* The coefficient can be used to determine the relative closeness of the two samples being considered. It is used to measure the separability of classes in classification and it is considered to be more reliable than the Mahalanobis distance, as the Mahalanobis distance is a particular case of the Bhattacharyya distance when the standard deviations of the two classes are the same. \n",
        "\n",
        "* Consequently, when two classes have similar means but different standard deviations, the Mahalanobis distance would tend to zero, whereas the Bhattacharyya distance grows depending on the difference between the standard deviations.\n",
        "\n",
        "* under certain conditions does not obey the triangle inequality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AVM3T1Dhkld",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Bhattacharyya_distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYLc2b-qsm8N",
        "colab_type": "text"
      },
      "source": [
        "**Hellinger Distance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEGZl1OtyhBy",
        "colab_type": "text"
      },
      "source": [
        "*  the Hellinger distance (closely related to, although different from, the Bhattacharyya distance) is used to quantify the similarity between two probability distributions. It is a type of f-divergence.\n",
        "\n",
        "* (?) ist vielleicht sogar eine metric weil es triangle inequality erf√ºllt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owVHpnpSywyW",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Hellinger_distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deNJWcC3hUSX",
        "colab_type": "text"
      },
      "source": [
        "**Yules Index**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGeN7197hXMA",
        "colab_type": "text"
      },
      "source": [
        "Yules Index ist ein statistischer Messwert, der die Uniformit√§t oder Diversit√§t des Wortschatzes bestimmt. Er wurde vom schottischen Statistiker George Udny Yule entwickelt und misst die Wahrscheinlichkeit, mit der zwei zuf√§llig ausgew√§hlte W√∂rter eines Textes identisch sind ‚Äì und zwar weitgehend unabh√§ngig vom Umfang des Textes.Diesen Index hat Herdan aufgegriffen und weiterentwickelt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-YLY8Q4hZmk",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Yules_Index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrVKpOHIzWHG",
        "colab_type": "text"
      },
      "source": [
        "##### **Types of Distance Measures**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvctBykzhmbB",
        "colab_type": "text"
      },
      "source": [
        "**Mahalanobis distance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-TZ_CmyyVV-",
        "colab_type": "text"
      },
      "source": [
        "* The Mahalanobis distance is a measure of the distance between a point P and a distribution D\n",
        "\n",
        "* If each of these axes is re-scaled to have unit variance, then the Mahalanobis distance corresponds to standard Euclidean distance in the transformed space. The Mahalanobis distance is thus unitless and scale-invariant, and takes into account the correlations of the data set.\n",
        "\n",
        "* In statistics, the covariance matrix of the data is sometimes used to define a distance metric called Mahalanobis distance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_w8YGJTtjaNV",
        "colab_type": "text"
      },
      "source": [
        "Bregman divergence (the Mahalanobis distance is an example of a Bregman divergence)\n",
        "\n",
        "Bhattacharyya distance related, for measuring similarity between data sets (and not between a point and a data set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guFweB6AhoJs",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Mahalanobis_distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtmj4FOHq6ht",
        "colab_type": "text"
      },
      "source": [
        "**Pearson Korrelationskoeffizient**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lydB1B0oq-VJ",
        "colab_type": "text"
      },
      "source": [
        "**Manhatten Distance L2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1hoL_o6Zh_H",
        "colab_type": "text"
      },
      "source": [
        "### **Metrics I: Durch Normen induzierte Metriken (L<sup>p</sup> Distances)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mISGLzNFniMx",
        "colab_type": "text"
      },
      "source": [
        "#### **Oberview**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yN_4QgtRm6rR",
        "colab_type": "text"
      },
      "source": [
        "**Jede Norm induziert eine Metrik, aber nicht jede Metrik wird durch eine Norm induziert** (?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBQAQ6GOZlg7",
        "colab_type": "text"
      },
      "source": [
        "Jede Norm auf einem Vektorraum induziert durch die Festlegung\n",
        "\n",
        "> $d(x, y) \\equiv\\|x-y\\|$\n",
        "\n",
        "eine Metrik. Somit ist jeder normierte Vektorraum (und erst recht jeder Innenproduktraum, Banachraum oder Hilbertraum) ein metrischer Raum.\n",
        "\n",
        "**Eine Metrik, die aus einer $p$ -Norm abgeleitet ist, hei√üt auch Minkowski-Metrik**. Wichtige Spezialf√§lle sind die\n",
        "\n",
        "* Manhattan-Metrik zu $p=1$, \n",
        "* euklidische Metrik zu $p=2$\n",
        "* Maximum-Metrik zu $p=\\infty$\n",
        "\n",
        "Weitere Beispiele f√ºr Normen (und damit auch f√ºr Metriken) finden sich im Artikel [Norm (Mathematik)](https://de.m.wikipedia.org/wiki/Norm_(Mathematik)). Aus einer $p$ -Norm abgeleitet sind zum Beispiel die Metriken der folgenden wichtigen R√§ume:\n",
        "der eindimensionale Raum der reellen oder komplexen Zahlen mit dem absoluten Betrag als Norm (mit beliebigem $p$ ) und der dadurch gegebenen Betragsmetrik\n",
        "\n",
        "> $d(x, y)=|x-y|$\n",
        "\n",
        "or euklidische Raum mit seiner durch den Satz des Pythagoras gegebenen euklidischen Metrik (zur euklidischen Norm f√ºr $p=2$ )\n",
        "\n",
        "> $d(x, y)=\\sqrt{\\left(x_{1}-y_{1}\\right)^{2}+\\cdots+\\left(x_{n}-y_{n}\\right)^{2}}$\n",
        "\n",
        "Als eine [**Fr√©chet-Metrik**](https://de.m.wikipedia.org/wiki/Fr√©chet-Metrik) wird gelegentlich eine Metrik\n",
        "\n",
        "> $d(x, y)=\\rho(x-y)$\n",
        "\n",
        "bezeichnet, die von einer Funktion $\\rho$ induziert wird, welche die meisten Eigenschaften einer Norm besitzt, aber nicht homogen ist. **Sie stellt eine Verbindung zwischen Metrik und Norm her.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbZOslj1eRla",
        "colab_type": "text"
      },
      "source": [
        "#### **L<sup>p</sup> Distances (Minkowski Distances / Metrics)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7Sd3MWyW5V6",
        "colab_type": "text"
      },
      "source": [
        "* **The Minkowski distance is a metric in a normed vector space** which can be considered as a generalization of both the Euclidean distance and the Manhattan distance.\n",
        "\n",
        "* Minkowski distance is typically used with p being 1 or 2, which correspond to the **Manhattan distance and the Euclidean distance**, respectively. In the limiting case of p reaching infinity, we obtain the **Chebyshev distance**\n",
        "\n",
        "* p need not be an integer, but it cannot be less than 1, because otherwise the triangle inequality does not hold (which is possible, but then it's not a metric anymore)\n",
        "\n",
        "* **In physical space the Euclidean distance is in a way the most natural one, because in this case the length of a rigid body does not change with rotation.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqKAYkW2oE2Z",
        "colab_type": "text"
      },
      "source": [
        "![alternativer Text](https://upload.wikimedia.org/wikipedia/commons/thumb/0/00/2D_unit_balls.svg/800px-2D_unit_balls.svg.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRP4WSD9oLvm",
        "colab_type": "text"
      },
      "source": [
        "*The figure shows unit circles (the set of all points that are at the unit distance from the centre) with various values of p*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2t8p1rGbdPx1",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Minkowski_distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFzrPn6HYJt9",
        "colab_type": "text"
      },
      "source": [
        "#### **L1 - Manhattan Distance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iO0nqUI8m_fA",
        "colab_type": "text"
      },
      "source": [
        "* **ist eine topologische Distanz**\n",
        "\n",
        "* The Manhattan norm gives rise to the Manhattan distance, where the distance between any two points, or vectors, is the sum of the differences between corresponding coordinates.\n",
        "\n",
        "* **Die Manhattan-Metrik ist die von der Summennorm (1-Norm) eines Vektorraums erzeugte Metrik. Aber: Die Summennorm ist nicht von einem Skalarprodukt induziert.**\n",
        "\n",
        "* Die Manhattan-Metrik (auch Manhattan-Distanz, Mannheimer Metrik, Taxi- oder Cityblock-Metrik) ist eine Metrik, in der die Distanz d zwischen zwei Punkten a und b als die Summe der absoluten Differenzen ihrer Einzelkoordinaten definiert wird:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oL_J1fZIqT8",
        "colab_type": "text"
      },
      "source": [
        "> $d(a, b)=\\sum_{i}\\left|a_{i}-b_{i}\\right|$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0_E7Gu4IbbP",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Manhattan-Metrik"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZlz94XCYE8Q",
        "colab_type": "text"
      },
      "source": [
        "#### **L2 - Euclidean Distance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1bl59wtmyYn",
        "colab_type": "text"
      },
      "source": [
        "* The **euclidean distance** is the L2-norm of the difference, **a special case of the Minkowski distance with p=2**. It is the natural distance in a geometric interpretation.\n",
        "\n",
        "> $d_{2}:(x, y) \\mapsto\\|x-y\\|_{2}=\\sqrt{d_{\\mathrm{SSD}}}=\\sqrt{\\sum_{i=1}^{n}\\left(x_{i}-y_{i}\\right)^{2}}$\n",
        "\n",
        "* Together with the Euclidean distance the Euclidean space is a metric space (x element R, d). http://theanalysisofdata.com/probability/B_4.html\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Euclidean_distance\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Tikhonov_regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ug1sNzCsdMGh",
        "colab_type": "text"
      },
      "source": [
        "#### **L ‚àû - Chebyshev Distance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QdrlGVRmlmx",
        "colab_type": "text"
      },
      "source": [
        "* The maximum norm gives rise to the **Chebyshev distance** or chessboard distance, the minimal number of moves a chess king would take to travel from x to y. The Chebyshev distance is the L‚àû-norm of the difference, a special case of the Minkowski distance where p goes to infinity. It is also known as Chessboard distance.\n",
        "\n",
        "> $d_{\\infty}:(x, y) \\mapsto\\|x-y\\|_{\\infty}=\\lim _{p \\rightarrow \\infty}\\left(\\sum_{i=1}^{n}\\left|x_{i}-y_{i}\\right|^{p}\\right)^{\\frac{1}{p}}=\\max _{i}\\left|x_{i}-y_{i}\\right|$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjWVKu82npHV",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Chebyshev_distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1mImehPm69J",
        "colab_type": "text"
      },
      "source": [
        "### **Metrics II: Nicht durch Normen erzeugte Metriken**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1tE5YQRlE54",
        "colab_type": "text"
      },
      "source": [
        "#### **Overview**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUnISc3anLSR",
        "colab_type": "text"
      },
      "source": [
        "* Auf jeder Menge l√§sst sich eine triviale Metrik, die sogenannte gleichm√§√üig diskrete Metrik (die sogar eine Ultrametrik ist) definieren durch \n",
        "\n",
        "> $d(x, y)=\\left\\{\\begin{array}{ll}0 & \\text { f√ºr } x=y \\\\ 1 & \\text { f√ºr } x \\neq y\\end{array}\\right.$\n",
        "\n",
        "Sie induziert die diskrete Topologie.\n",
        "\n",
        "* Auf $\\mathbb{R}$ wird durch $\\delta(x, y)=|\\arctan (x)-\\arctan (y)|$ eine Metrik definiert. Bez√ºglich dieser Metrik ist $\\mathbb{R}$ nicht vollst√§ndig. So ist $z .$ B. die Folge $(n)_{n \\in \\mathbb{N}}$ eine $\\delta$ -Cauchy-Folge, die nicht in $\\mathbb{R}$ konvergiert. Die von dieser Metrik erzeugte Topologie stimmt zwar mit der Standardtopologie auf IR √ºberein, aber die von den beiden Metriken induzierten uniformen Strukturen sind offensichtlich\n",
        "verschieden.\n",
        "\n",
        "Im Allgemeinen **nicht durch eine Norm induziert ist die riemannsche Metrik**, die aus einer differenzierbaren Mannigfaltigkeit eine [riemannsche Mannigfaltigkeit](https://en.m.wikipedia.org/wiki/Riemannian_manifold) macht. \n",
        "\n",
        "Beispiele daf√ºr:\n",
        "\n",
        "* die nat√ºrliche Metrik auf einer Kugeloberfl√§che, in der der Gro√ükreis die k√ºrzeste Verbindung ([Geod√§te](https://en.m.wikipedia.org/wiki/Geodesic)) zwischen zwei Punkten ist;\n",
        "\n",
        "* die uneigentliche Metrik im Minkowski-Raum $\\mathbb{R} \\times \\mathbb{R}^{3}$ der speziellen Relativit√§tstheorie, in der zeit√§hnliche Abst√§nde durch $\\left[(\\Delta t)^{2}-(\\Delta x / c)^{2}-(\\Delta y / c)^{2}-(\\Delta z / c)^{2}\\right]^{1 / 2}$ und orts√§hnliche Abst√§nde $\\operatorname{durch}\\left[(\\Delta x)^{2}+(\\Delta y)^{2}+(\\Delta z)^{2}-(\\Delta c t)^{2}\\right]^{1 / 2}$ gegeben sind\n",
        "\n",
        "* die von der Materieverteilung abh√§ngige Verallgemeinerung dieser Metrik in der allgemeinen Relativit√§tstheorie."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbhUmt563M6H",
        "colab_type": "text"
      },
      "source": [
        "Die riemannsche Metrik ist keine Metrik im Sinne der Theorie der metrischen R√§ume, sondern ein Skalarprodukt. Man kann jedoch √§hnlich wie in der Theorie der Skalarproduktr√§ume aus dem Skalarprodukt eine Metrik gewinnen. Somit k√∂nnen riemannsche Mannigfaltigkeiten als metrische R√§ume verstanden werden. Auf riemannschen Mannigfaltigkeiten sind also im Gegensatz zu differenzierbaren Mannigfaltigen Begriffe wie Abstand, Durchmesser oder Vollst√§ndigkeit definiert."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUzTHdhL3PTo",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Riemannsche_Mannigfaltigkeit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taLU82-Xn0xm",
        "colab_type": "text"
      },
      "source": [
        "* Die [franz√∂sische Eisenbahnmetrik](https://de.m.wikipedia.org/wiki/Franz√∂sische_Eisenbahnmetrik) ist ein beliebtes √úbungsbeispiel f√ºr eine nicht durch eine Norm induzierte Metrik. Sie wird unter Bezugnahme auf einen ausgezeichneten Punkt $P($, Paris\") wie folgt definiert: Der Abstand zweier verschiedener Punkte, deren Verbindungsgerade durch $P$ verl√§uft, ist inr Abstand unter der gew√∂hnlichen euklidischen Metrik. Der Abstand zweier\n",
        "verschiedener Punkte, deren Verbindungsgerade nicht durch $P$ verl√§uft, ist die Summe ihrer Abst√§nde von $P$\n",
        "\n",
        "* Die [Hausdorff-Metrik](https://de.m.wikipedia.org/wiki/Hausdorff-Metrik) misst den Abstand zwischen Teilmengen, nicht Elementen, eines metrischen Raums; man k√∂nnte sie als Metrik zweiten Grades bezeichnen, denn sie greift auf eine Metrik ersten Grades zwischen den Elementen des metrischen Raums zur√ºck.\n",
        "\n",
        "* Der [Hamming-Abstand](https://de.m.wikipedia.org/wiki/Hamming-Abstand) ist eine Metrik auf dem Coderaum, die die Unterschiedlichkeit von (gleich langen) Zeichenketten angibt. Siehe auch [Levenshetin Distance](https://de.m.wikipedia.org/wiki/Levenshtein-Distanz) - Die Levenshtein-Distanz kann als Erweiterung des Hamming-Abstands angesehen werden, welcher sich auf Ersetzungen beschr√§nkt und daher nur Zeichenketten gleicher L√§nge bemessen kann. Eine Phonetische Suche kann die Levenshtein-Distanz verwenden, um Fehler zu erlauben. [Dynamic Time Warpening](https://de.m.wikipedia.org/wiki/Dynamic-Time-Warping). Die Levenshtein-Distanz kann als Sonderform der Dynamic-Time-Warping-Distanz (DTW) betrachtet werden."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFheGZB5u2fk",
        "colab_type": "text"
      },
      "source": [
        "#### **Edit Distance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh03tQ74ulO-",
        "colab_type": "text"
      },
      "source": [
        "In computer science, there is the notion of the \"edit distance\" between two strings. For example, the words \"dog\" and \"dot\", which vary by only one letter, are closer than \"dog\" and \"cat\", which differ by three letters. This idea is used in spell checkers and in coding theory, and is mathematically formalized in several different ways, such as:\n",
        "\n",
        "[Levenshtein distance](https://en.m.wikipedia.org/wiki/Levenshtein_distance)\n",
        "\n",
        "[Hamming distance](https://en.m.wikipedia.org/wiki/Hamming_distance)\n",
        "\n",
        "[Lee distance](https://en.m.wikipedia.org/wiki/Lee_distance)\n",
        "\n",
        "[Jaro‚ÄìWinkler distance](https://en.m.wikipedia.org/wiki/Jaro‚ÄìWinkler_distance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJpF7K2iugN3",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Edit_distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mbesBmkiMUh",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Metrischer_Raum"
      ]
    }
  ]
}